% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions.R
\name{sparselink}
\alias{sparselink}
\title{Sparse regression for related problems}
\usage{
sparselink(
  x,
  y,
  family,
  alpha.init = 0.95,
  alpha = 1,
  type = "exp",
  nfolds = 10,
  trial = FALSE
)
}
\arguments{
\item{x}{\eqn{n \times p} matrix (multi-task learning) 
or list of \eqn{n_k \times p} matrices (transfer learning)}

\item{y}{\eqn{n \times q} matrix (multi-task learning)
or list of \eqn{n_k}-dimensional vectors (transfer learning)}

\item{family}{character \code{"gaussian"} or \code{"binomial"}}

\item{alpha.init}{elastic net mixing parameter for initial regressions,
default: 0.95 (lasso-like elastic net)}

\item{alpha}{elastic net mixing parameter of final regressions,
default: 1 (lasso)}

\item{type}{character}

\item{nfolds}{number of cross-validation folds}

\item{trial}{experimental argument (to be removed):
Should exponents above 1 be used? Default: \code{FALSE}}
}
\value{
Returns an object of class \code{sparselink}, a list with multiple slots.
- Stage 1 regressions (before sharing information):
Slot \code{glm.one} contains \eqn{q} objects of type \code{cv.glmnet}
(one for each problem).
- Candidate scaling parameters (exponents):
Slot \code{weight} contains a data frame
with \eqn{n} combinations of exponents
for the external (source) and internal (target) weights
- Stage 2 regressions (after sharing information):
Slot \code{glm.two} contains \eqn{q} lists (one for each problem)
of \eqn{n} objects of type \code{cv.glmnet}
(one for each combination of exponents).
- Optimal regularisation parameters: 
Slot \code{lambda.min} contains the cross-validated regularisation parameters
for the stage 2 regressions.
- Optimal scaling parameters:
Slots \code{weight.ind}/\code{weight.min}
indicate/contain the cross-validated scaling parameters.
}
\description{
Estimates sparse regression models (i.e., selecting few variables)
in multi-task learning or transfer learning
}
\examples{
# multi-task learning
n <- 100
p <- 50
q <- 3
family <- "gaussian"
x <- matrix(data=rnorm(n=n*p),nrow=n,ncol=p)
y <- matrix(data=rnorm(n*q),nrow=n,ncol=q)
object <- sparselink(x=x,y=y,family=family)

# transfer learning
n <- c(100,50)
p <- 50
x <- lapply(X=n,function(x) matrix(data=stats::rnorm(n*p),nrow=x,ncol=p))
y <- lapply(X=n,function(x) stats::rnorm(x))
family <- "gaussian"
object <- sparselink(x=x,y=y,family=family)

}
