[{"path":"https://rauschenberger.github.io/sparselink/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing guidelines","title":"Contributing guidelines","text":"encounter bug R package sparselink, please report GitHub Issues. Ideally, provide minimal reproducible example (.e., lines code can copy--paste R console obtain error).","code":""},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"working-environment","dir":"Articles","previous_headings":"","what":"Working environment","title":"Analysis code","text":"vignette includes code chunks long computation time (e.g., analysing simulated experimental data) code chunks short computation time (e.g., generating figures tables). logical options sim.app fig.tab determine whether chunks () running simulation application (ii) generating figures tables evaluated, respectively. Running vignette sim.app=FALSE fig.tab=TRUE means figures tables generated previously obtained results. Running vignette sim.app=TRUE fig.tab=TRUEand means results reproduced (including data download data processing). also possible execute individual chunks (e.g., reproducing specific figure table), important provide required inputs (e.g., “Requires: file X folder Y, execution chunk Z”). chunk verifies working environment. working directory, specified object path, must contain R functions “package/R/functions.R” well folders “results” “manuscript”. Alternatively, R functions can loaded R package sparselink. chunk also installs missing R packages CRAN Bioconductor.","code":"knitr::opts_chunk$set(echo=TRUE,eval=FALSE) sim.app <- FALSE # reproduce simulation and application? fig.tab <- FALSE # reproduce figures and tables? path <- \"C:/Users/arauschenberger/Desktop/sparselink\" # LIH (Windows) #path <- \"/Users/armin.rauschenberger/Desktop/LIH/sparselink\" # LCSB (Mac)  dir <- c(\"results\",\"manuscript\",\"package/R/functions.R\") for(i in seq_along(dir)){   if(!dir.exists(file.path(path,dir[i]))&!file.exists(file.path(path,dir[i]))){     stop(paste0(\"Require folder/file'\",dir[i],\"'.\"))   }  } source(file.path(path,\"package/R/functions.R\")) # Or load 'sparselink' package.  inst <- rownames(utils::installed.packages()) pkgs <- c(\"knitr\",\"rmarkdown\",\"glmnet\",\"BiocManager\",\"mvtnorm\",\"glmtrans\",\"spls\",\"xrnet\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     utils::install.packages(pkgs[i])   } } pkgs <- c(\"recount3\",\"edgeR\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     BiocManager::install(pkgs[i])   } }  blue <- \"blue\"; red <- \"red\"  if(exists(\"sim.app\")&exists(\"fig.tab\")){   if(!sim.app&fig.tab){     files <- c(\"simulation_multiple.RData\",\"simulation_transfer.RData\",\"recount3_data.RData\",\"explore_data.RData\",\"application.RData\")     for(i in seq_along(files)){       if(!file.exists(file.path(path,\"results\",files[i]))){         stop(\"File\",files[i],\"is missing.\")       }     }   } }"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Analysis code","text":"chunk generates figure methods section. Requires: execution chunk setup Execution time: \\(1\\) second Ensures: file fig_flow.eps folder manuscript","code":"#<<setup>>  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_flow.eps\"),width=6,height=2.5) graphics::par(mfrow=c(1,1),mar=c(0,0,0,0)) graphics::plot.new() graphics::plot.window(xlim=c(-0.2,1.0),ylim=c(0.0,1.0)) cex <- 0.8  pos <- data.frame(left=0.2,right=0.8,top=0.8,centre=0.45,bottom=0.1) mar <- data.frame(vertical=0.08,horizontal=0.08,dist=0.04)  graphics::text(labels=paste(\"problem\",1:2),x=c(pos$left,pos$right),y=pos$top+2*mar$vertical,font=2,col=c(blue,red),cex=cex) graphics::text(labels=expression(hat(beta)[\"j,1\"]^{init}),x=pos$left,y=pos$top,col=blue) graphics::text(labels=expression(hat(beta)[\"j,2\"]^{init}),x=pos$right,y=pos$top,col=red)  graphics::arrows(x0=rep(c(pos$left,pos$right),each=2),x1=rep(c(pos$left,pos$right),times=2)+c(-mar$horizontal,-mar$horizontal,mar$horizontal,mar$horizontal),y0=pos$top-mar$vertical,y1=pos$centre+mar$vertical,length=0.1,col=rep(c(blue,red),each=2),lwd=2)  graphics::text(labels=expression(w[\"j,1\"]^{int}),x=pos$left-mar$horizontal-mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"p+j,1\"]^{int}),x=pos$left-mar$horizontal+mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"j,1\"]^{ext}),x=pos$left+mar$horizontal-mar$dist,y=pos$centre,col=red) graphics::text(labels=expression(w[\"p+j,1\"]^{ext}),x=pos$left+mar$horizontal+mar$dist,y=pos$centre,col=red)  graphics::text(labels=expression(w[\"j,2\"]^{ext}),x=pos$right-mar$horizontal-mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"p+j,2\"]^{ext}),x=pos$right-mar$horizontal+mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"j,2\"]^{int}),x=pos$right+mar$horizontal-mar$dist,y=pos$centre,col=red) graphics::text(labels=expression(w[\"p+j,2\"]^{int}),x=pos$right+mar$horizontal+mar$dist,y=pos$centre,col=red)  graphics::arrows(x0=c(pos$left,pos$right),y0=pos$centre-mar$vertical,y1=pos$bottom+mar$vertical,col=c(blue,red),length=0.1,lwd=2) graphics::text(labels=expression(hat(beta)[\"j,1\"]^{final}==hat(gamma)[\"j,1\"]-hat(gamma)[\"p+j,1\"]),x=pos$left,y=pos$bottom,col=blue) graphics::text(labels=expression(hat(beta)[\"j,2\"]^{final}==hat(gamma)[\"j,2\"]-hat(gamma)[\"p+j,2\"]),x=pos$right,y=pos$bottom,col=red)  graphics::text(x=-0.1,y=c(pos$top,pos$bottom),labels=paste(\"stage\",1:2),font=2,cex=cex) grDevices::dev.off()"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Analysis code","text":"chunk performs simulation. Requires: execution chunk setup Execution time: 0.5 hours Ensures: files simulation_transfer.RData (transfer learning), simulation_multiple.RData (multi-task learning) info_sim.txt (session information) folder results following chunk generate figures simulation study. Requires: execution chunk setup, files simulation_transfer.RData simulation_multiple.RData folder results (generated chunk simulation) execution time: \\(1\\) second Ensures: files fig_sim_multiple.eps fig_sim_transfer.eps folder manuscript","code":"#<<setup>>  alpha.init <- 0.95; type <- \"exp\";  repetitions <- 10  for(mode in c(\"transfer\",\"multiple\")){      grid <- expand.grid(prob.separate=c(0.0,0.025,0.05),prob.common=c(0.0,0.025,0.05),family=\"gaussian\")   grid <- grid[rep(seq_len(nrow(grid)),each=repetitions),] #   grid$seed <- seq_len(nrow(grid))   grid$family <- as.character(grid$family)   deviance <- auc <- time <- mse.coef <- mse.zero <- mse.nzero <- sel.num <- sel.coef <- sel.count <- hyperpar <- list()   for(i in seq(from=1,to=nrow(grid))){     set.seed(seed=grid$seed[i])     cat(\"i=\",i,\"\\n\")     if(mode==\"transfer\"){       data <- sim.data.transfer(prob.common=grid$prob.common[i],prob.separate=grid$prob.separate[i],family=grid$family[i])       method <- c(\"glm.separate\",\"glm.glmtrans\",\"sparselink\",\"glm.xrnet\")     } else if(mode==\"multiple\"){       #--- multi-task learning ---       data <- sim.data.multiple(prob.common=grid$prob.common[i],prob.separate=grid$prob.separate[i],family=grid$family[i])       method <- c(\"glm.separate\",\"glm.mgaussian\",\"sparselink\",\"glm.spls\") # add glmnet \"mgaussian\" (only for linear case) or \"MTPS\" (not sparse)?     }          result <- traintest(y_train=data$y_train,X_train=data$X_train,y_test=data$y_test,X_test=data$X_test,family=grid$family[i],method=method,alpha.init=alpha.init,type=type,alpha=1,trial=FALSE)     hyperpar[[i]] <- result$hyperpar     time[[i]] <- result$time     auc[[i]] <- result$auc     deviance[[i]] <- result$deviance     sel.num[[i]] <- t(sapply(result$coef,function(x) colSums(x!=0)))     sel.count[[i]] <- t(sapply(result$coef,function(x) rowMeans(count_matrix(truth=sign(data$beta),estim=sign(x))))) # Add na.rm=TRUE?          sel.coef[[i]] <- t(sapply(result$coef,function(x) colMeans(sign(x)!=sign(data$beta))))     # CONTINUE HERE: consider sparsity, true positives, false negatives, signs          mse.coef[[i]] <- t(sapply(result$coef,function(x) colMeans((data$beta-x)^2)))     mse.zero[[i]] <- t(sapply(result$coef,function(x) colMeans(((data$beta==0)*(data$beta-x))^2)))     mse.nzero[[i]] <- t(sapply(result$coef,function(x) colMeans(((data$beta!=0)*(data$beta-x))^2)))   }   save(grid,deviance,auc,sel.num,sel.count,sel.coef,mse.coef,mse.zero,mse.nzero,time,file=file.path(path,\"results\",paste0(\"simulation_\",mode,\".RData\"))) }  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),      sessioninfo::session_info()),con=paste0(path,\"/results/info_sim.txt\")) #<<setup>>  caption <- paste(c(\"\\\\textbf{Multi-task learning.}\",\"\\\\textbf{Transfer learning.}\"),\"Comparison of different measures (rows) between an available method (red) and the proposed method (blue) in different simulation settings (columns), based on the average of three problems\",c(\"(tasks)\",\"(datasets)\"),\"for each repetition out of ten. Measures: performance metric (mean squared error on hold-out data, as a fraction of the one from standard lasso regression; a point below the dashed line means that\",c(\"multi-task\",\"transfer\"),\"learning improves predictions), sparsity (number of non-zero coefficients), precision (number of coefficients with correct signs divided by number of non-zero coefficients). The arrows point in the direction of improvement. Settings: percentage of features with a common effect for all problems ($\\\\pi_\\\\theta$), percentage of features with a specific effect for each problem ($\\\\pi_\\\\delta$).\",c(\"\\\\label{fig_sim_multiple}\",\"\\\\label{fig_sim_transfer}\"))  figure_change <- function(model0,model1=\"sparselink\",model2){      mode <- paste0(100*grid$prob.common,\"%\\n\",100*grid$prob.separate,\"%\")      graphics::par(mfrow=c(3,1),mar=c(3,3,1,1))      label <- function(){     cex <- 0.5     at <- 0.3     graphics::mtext(text=expression(pi[theta]==phantom(.)),side=1,line=0.2,at=at,cex=cex)     graphics::mtext(text=expression(pi[delta]==phantom(.)),side=1,line=1.2,at=at,cex=cex)   }      #--- predictive performance ---   means <- t(sapply(X=deviance,FUN=rowMeans))   means <- means/means[,\"glm.separate\"]   change(x=mode,y0=means[,model0],y1=means[,model1],y2=means[,model2],main=\"metric\",increase=FALSE)   graphics::abline(h=1,lty=2,col=\"grey\")   label()      #--- sparsity ---   nzero <- sapply(X=sel.num,FUN=rowMeans)   change(x=mode,y0=nzero[model0,],y1=nzero[model1,],y2=nzero[model2,],main=\"sparsity\",increase=FALSE)      graphics::abline(h=0,lty=2,col=\"grey\")   label()      #--- precision ---   precision <- sapply(X=sel.count,FUN=function(x) x[,\"precision\"])   precision[is.na(precision)] <- 0   change(x=mode,y0=precision[model0,],y1=precision[model1,],y2=precision[model2,],main=\"precision\",increase=TRUE)      graphics::abline(h=0,lty=2,col=\"grey\")   label()    }  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_sim_multiple.eps\"),width=6.5,height=6) load(file.path(path,paste0(\"results/simulation_multiple.RData\")),verbose=TRUE) #model.ref <- \"glm.mgaussian\" #model.own <- \"sparselink\" figure_change(model0=\"glm.mgaussian\",model1=\"sparselink\",model2=\"glm.spls\") rowMeans(sapply(deviance,function(x) rank(rowMeans(x)))) rowMeans(sapply(deviance,function(x) colMeans(t(x)/x[\"glm.separate\",]))) runtime <- rowSums(sapply(time,function(x) x)) round(runtime/runtime[\"glm.separate\"],digits=2) grDevices::dev.off()  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_sim_transfer.eps\"),width=6.5,height=6) load(file.path(path,paste0(\"results/simulation_transfer.RData\"))) #model.ref <- \"glm.glmtrans\" #model.own <- \"sparselink\" figure_change(model0=\"glm.glmtrans\",model1=\"sparselink\",model2=\"glm.xrnet\") rowMeans(sapply(deviance,function(x) rank(rowMeans(x)))) rowMeans(sapply(deviance,function(x) colMeans(t(x)/x[\"glm.separate\",]))) runtime <- rowSums(sapply(time,function(x) x)) round(runtime/runtime[\"glm.separate\"],digits=2) grDevices::dev.off()"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"sample-size-and-sparsity-under-development","dir":"Articles","previous_headings":"Simulation","what":"Sample size and sparsity (under development)","title":"Analysis code","text":"","code":"# Effect of sample size in source or target dataset (TL), effect of sample size (MTL). #<<setup>>  alpha.init <- 0.95; type <- \"exp\";  repetitions <- 50 # was repetitions <- 10 grid <- metric <- list()  for(mode in c(\"MTL-size\",\"TL-source\",\"TL-target\")){ #,\"TL-prop\",\"MTL-prop\"   metric[[mode]] <- list()   cand <- c(20,40,60,80,100)   if(mode==\"MTL-size\"){     grid[[mode]] <- expand.grid(prob.common=0.05,prob.separate=0.025,family=\"gaussian\",n0=cand)   } else if(mode==\"TL-source\"){     grid[[mode]] <- expand.grid(prob.common=0.05,prob.separate=0.025,family=\"gaussian\",n_source=cand,n_target=50)   } else if(mode==\"TL-target\"){     grid[[mode]] <- expand.grid(prob.common=0.05,prob.separate=0.025,family=\"gaussian\",n_source=50,n_target=cand)   } else if(mode %in% c(\"TL-prop\",\"MTL-prop\")){     cand <- c(0.025,0.05,0.10,0.15,0.20)     grid[[mode]] <- expand.grid(prob.common=cand,prob.separate=NA,family=\"gaussian\",n_source=50,n_target=50,n0=50)   } else {     stop(\"Wrong mode.\")   }   grid[[mode]] <- grid[[mode]][rep(seq_len(nrow(grid[[mode]])),each=repetitions),]   #grid[[mode]]$seed <- seq_len(nrow(grid[[mode]]))   grid[[mode]]$seed <- rep(x=seq_len(repetitions),times=length(cand))   grid[[mode]]$family <- as.character(grid[[mode]]$family)   cond <- is.na(grid[[mode]]$prob.separate)   grid[[mode]]$prob.separate[cond] <- 0.5*grid[[mode]]$prob.common[cond]      for(i in seq(from=1,to=nrow(grid[[mode]]))){       set.seed(seed=grid$seed[i])       cat(\"i=\",i,\"\\n\")       if(mode %in% c(\"TL-source\",\"TL-target\",\"TL-prop\")){         n0 <- rep(c(grid[[mode]]$n_source[i],grid[[mode]]$n_target[i]),times=c(2,1))         data <- sim.data.transfer(prob.common=grid[[mode]]$prob.common[i],prob.separate=grid[[mode]]$prob.separate[i],family=grid[[mode]]$family[i],n0=n0)         method <- c(\"glm.separate\",\"glm.glmtrans\",\"sparselink\",\"glm.xrnet\")       } else if(mode %in% c(\"MTL-size\",\"MTL-prop\")){         data <- sim.data.multiple(prob.common=grid[[mode]]$prob.common[i],prob.separate=grid[[mode]]$prob.separate[i],family=grid[[mode]]$family[i],n0=grid[[mode]]$n0[i])         method <- c(\"glm.separate\",\"glm.mgaussian\",\"sparselink\",\"glm.spls\")       } else {         stop(\"Wrong mode.\")       }       result <- traintest(y_train=data$y_train,X_train=data$X_train,y_test=data$y_test,X_test=data$X_test,family=grid[[mode]]$family[i],method=method,alpha.init=alpha.init,type=type,alpha=1,trial=FALSE)       metric[[mode]][[i]] <- result$deviance     } }  save(grid,metric,file=file.path(path,\"results\",\"simulation_devel.RData\")) #<<setup>> load(file.path(path,\"results\",\"simulation_devel.RData\"))  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_sim_extra.eps\"),width=6.5,height=3) cex <- 0.8 graphics::par(mfrow=c(1,3),mar=c(4.5,4.5,1.5,1),oma=c(0,0,0,0)) #graphics::layout(mat=matrix(data=c(1,1,2,2,3,3,0,4,4,0,5,5),ncol=2)) for(mode in c(\"MTL-size\",\"TL-source\",\"TL-target\")){ #for(mode in c(\"MTL-prop\",\"TL-prop\")){   if(mode %in% c(\"MTL-size\",\"MTL-prop\",\"TL-prop\")){     mse <- sapply(metric[[mode]],function(x) rowMeans(x))   } else if(mode %in% c(\"TL-source\",\"TL-target\")){     mse <- sapply(metric[[mode]],function(x) x[,3])   }   if(mode %in% c(\"TL-source\",\"TL-target\",\"TL-prop\")){     col <- c(\"glm.separate\"=\"black\",\"glm.glmtrans\"=\"red\",\"glm.xrnet\"=\"orange\",\"sparselink\"=\"blue\")     lty <- c(\"glm.separate\"=3,\"glm.glmtrans\"=2,\"glm.xrnet\"=2,\"sparselink\"=1)   } else if(mode %in% c(\"MTL-size\",\"MTL-prop\")) {     col <- c(\"glm.separate\"=\"black\",\"glm.mgaussian\"=\"red\",\"glm.spls\"=\"orange\",\"sparselink\"=\"blue\")     lty <- c(\"glm.separate\"=3,\"glm.mgaussian\"=2,\"glm.spls\"=2,\"sparselink\"=1)   }   if(mode==\"TL-source\"){     params <- grid[[mode]]$n_source   } else if(mode==\"TL-target\"){     params <- grid[[mode]]$n_target   } else if(mode==\"MTL-size\"){     params <- grid[[mode]]$n0   } else if(mode %in% c(\"TL-prop\",\"MTL-prop\")){     params <- grid[[mode]]$prob.common   }   unique <- unique(params)   graphics::plot.new()   graphics::plot.window(xlim=range(params),ylim=range(log(mse)))   graphics::box()   if(mode==\"MTL-size\"){     main <- \"MTL - varying sample size\"     xlab <- bquote(\"sample size (\"~n[1]~\"=\"~n[2]~\"=\"~n[3]~\")\")     legend <- \"\"   } else if(mode==\"TL-source\"){     main <- \"TL - varying source sample size\"     xlab <- bquote(\"source sample size (\"~n[1]~\"=\"~n[2]~\")\")     legend <- bquote(\"target sample size:\"~n[3]==.(unique(grid[[mode]]$n_target)))   } else if(mode==\"TL-target\"){     main <- \"TL - varying target sample size\"     xlab <- bquote(\"target sample size (\"~n[3]~\")\")     legend <- bquote(\"source sample size:\"~n[1]~\"=\"~n[2]==.(unique(grid[[mode]]$n_source)))   } else if(mode==\"MTL-prop\"){     xlab <- \"blabla\"     main <- \"MTL - effect proportion\"     legend <- \"\"   } else if(mode==\"TL-prop\"){     xlab <- \"blabla\"     main <- \"TL - effect proportion\"     legend <- \"\"   }   graphics::title(main=main,cex.main=cex)   graphics::title(ylab=\"log MSE\",line=2.5,xlab=xlab,cex.lab=cex)   graphics::legend(x=\"topleft\",legend=legend,bty=\"n\",cex=cex)   if(mode %in% c(\"TL-prop\",\"MTL-prop\")){     graphics::axis(side=1,at=unique,labels=paste0(100*unique,\"%\"),cex.axis=cex)   } else {     graphics::axis(side=1,at=unique,cex.axis=cex)   }   graphics::axis(side=2,cex.axis=cex)      for(i in names(col)){     val <- tapply(X=mse[i,],INDEX=params,FUN=function(x) mean(x))     graphics::lines(x=unique,y=log(val),col=col[i],type=\"o\",pch=16,lty=lty[i])   } } grDevices::dev.off()  # Change settings so that competing methods are useful."},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"data-preparation","dir":"Articles","previous_headings":"Application","what":"Data preparation","title":"Analysis code","text":"chunk defines references project identifiers application. Requires: nothing Execution time: \\(1\\) second Ensures: list project working environment chunk downloads data application. Requires: execution chunks setup define_projects Execution time: depends internet speed cached files Ensures: files recount3_data.RData (data sets) info_data.txt (system information) folder results chunk preprocesses data. Requires: execution chunks setup define_projects, file recount3_data.RData (generated chunk download_data) Execution time: \\(5\\) seconds Ensures: lists y (targets) x (features) working environment","code":"project <- list() project$IBD <- c(\"Tew (2016)\"=\"SRP063496\",                  \"Haberman (2019)\"=\"SRP129004\",                  \"Verstockt (2019)\"=\"ERP113396\",                  \"Verstockt (2020)\"=\"ERP114636\",                  \"Boyd (2018)\"=\"SRP100787\") project$RA <- c(\"Baker (2019)\"=\"SRP169062\",                 \"Moncrieffe (2017)\"=\"SRP074736\",                 \"Goldberg (2018)\"=\"SRP155483\") extra <- c(\"Lewis (2019)\"=\"ERP104864\") # https://doi.org/10.1016/j.celrep.2019.07.091 #<<setup>> #<<define_projects>>  data <- list() for(i in c(unlist(project),extra)){   data[[i]] <- recount3::create_rse_manual(     project=i,     project_home=\"data_sources/sra\",     organism=\"human\",     annotation = \"gencode_v26\",     type=\"gene\") } save(data,file=file.path(path,\"results/recount3_data.RData\"))  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),       sessioninfo::session_info()),con=paste0(path,\"/results/info_data.txt\")) #<<setup>> #<<define_projects>>  load(file.path(path,\"results/recount3_data.RData\"))  #- - - - - - - - - - - - - - - #- - - extract features  - - -  #- - - - - - - - - - - - - - -  # extract features x <- list() for(i in c(unlist(project),extra)){   counts <- t(SummarizedExperiment::assays(data[[i]])$raw_counts)   colnames(counts) <- SummarizedExperiment::rowRanges(data[[i]])$gene_name   x[[i]] <- counts }  # select most expressed protein-coding genes (for all TL projects together) select <- list() total <- numeric() for(i in unlist(project)){   #total <- rbind(total,Matrix::colSums(x[[i]])) # original: mean filtering   total <- rbind(total,apply(X=x[[i]],MARGIN=2,FUN=stats::var)) # trial: variance filtering } type <- SummarizedExperiment::rowData(data[[i]])$gene_type cond <- type==\"protein_coding\" total[,!cond] <- 0 rank <- apply(X=total,MARGIN=1,FUN=rank) mean_rank <- rowMeans(rank) #temp <- cond & apply(total,2,function(x) all(x>0)) & (mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[2000]) # original: top 2000 temp <- cond & mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[5000] # trial: top 5000  for(i in unlist(project)){   select[[i]] <- temp }  # select most expressed protein-coding genes (for MTL project) #mean <- apply(X=x[[extra]],MARGIN=2,FUN=mean) # original var <- apply(X=x[[extra]],MARGIN=2,FUN=var) # trial #warning(\"change number in next line\") #temp <- cond & mean >= sort(mean[cond],decreasing=TRUE)[5000] # trial: top 5000 temp <- cond & var >= sort(var[cond],decreasing=TRUE)[5000] # trial: top 5000 select[[extra]] <- temp  # pre-processing for(i in c(unlist(project),extra)){   lib.size <- Matrix::rowSums(x[[i]])   x[[i]] <- x[[i]][,select[[i]],drop=FALSE]   norm.factors <- edgeR::calcNormFactors(object=t(x[[i]]),lib.size=lib.size)   gamma <- norm.factors*lib.size/mean(lib.size)   gamma <- matrix(data=gamma,nrow=nrow(x[[i]]),ncol=ncol(x[[i]]))   x[[i]] <- x[[i]]/gamma   x[[i]] <- 2*sqrt(x[[i]] + 3/8) # Anscombe transform   x[[i]] <- scale(x[[i]]) # scale because of different datasets!? }  #- - - - - - - - - - - - - - #- - - extract targets - - - #- - - - - - - - - - - - - -  # extract information on samples frame <- list() for(i in c(unlist(project),extra)){   list <- strsplit(data[[i]]$sra.sample_attributes,split=\"\\\\|\")   data[[i]]$sra.experiment_attributes   # What about sra.experiment_attributes?   n <- length(list)   cols <- unique(sapply(strsplit(unlist(list),split=\";;\"),function(x) x[1]))   ncol <- length(cols)   frame[[i]] <- matrix(data=NA,nrow=n,ncol=ncol,dimnames=list(rownames(x[[i]]),cols))   for(j in seq_len(n)){     for(k in seq_len(ncol)){       vector <- list[[j]]       which <- which(substring(text=vector,first=1,last=nchar(cols[k]))==cols[k])       string <- vector[which]       if(length(string)==0){next}       frame[[i]][j,k] <- strsplit(string,split=\";;\")[[1]][2]     }   }   frame[[i]] <- as.data.frame(frame[[i]]) }  # extract binary outcome y <- z <- list() for(i in unlist(project)){   # CONTINUE HERE!!!   if(i==\"ERP113396\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical history`,FUN=function(x) switch(EXPR=x,\"responder\"=1,\"non-responder\"=0,stop(\"invalid\")))   } else if(i==\"ERP114636\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical information`,FUN=function(x) switch(EXPR=x,\"response to vedolizumab therapy\"=1-1,\"no response to vedolizumab therapy\"=0+1,stop(\"invalid\")))     warning(\"Inverting response and non-response!\")   } else if(i==\"SRP100787\"){     y[[i]] <- sapply(X=frame[[i]]$condition,FUN=function(x) switch(EXPR=x,\"CD inactive\"=1,\"UC inactive\"=1,\"CD active\"=0,\"UC active\"=0,control=NA,\"NA\"=NA,stop(\"invalid\")))   } else if(i==\"SRP129004\"){     y[[i]] <- sapply(X=frame[[i]]$`week 4 remission`,FUN=function(x) switch(EXP=x,\"Yes\"=1,\"No\"=0,\"NA\"=NA,stop(\"invalid\")))     suppressWarnings(z[[i]] <- data.frame(pucai=as.numeric(frame[[i]]$pucai),mayo=as.numeric(frame[[i]]$`total mayo score`),histology=as.numeric(frame[[i]]$`histology severity score`)))   } else if(i==\"SRP063496\"){     y[[i]] <- sapply(X=frame[[i]]$`remission at week 10`,FUN=function(x) switch(x, \"Remitter\"=1,\"Non-remitter\"=0,\"N/A\"=NA,stop(\"invalid\")))   } else if(i==\"SRP169062\"){     y[[i]] <- sapply(X=frame[[i]]$`flare event`,FUN=function(x) switch(x,\"no flare\"=1,\"flare\"=0,stop(\"invalid\")))   } else if(i==\"SRP155483\"){     y[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=1,\"Low\"=0,\"Moderate\"=0,\"High\"=0,\"--\"=NA,stop(\"invalid\")))     z[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=0,\"Low\"=1,\"Moderate\"=2,\"High\"=3,\"--\"=NA,stop(\"invalid\")))   } else if(i==\"SRP074736\"){     y[[i]] <- sapply(X=frame[[i]]$`mtx response status`,FUN=function(x) switch(x,\"responder\"=1,\"non-responder\"=0,\"control\"=NA,stop(\"invalid\")))   } }  # overlap for(j in unlist(project)){   is.na <- is.na(y[[j]])   if(length(is.na)!=nrow(x[[j]])){stop()}   y[[j]] <- y[[j]][!is.na]   if(!is.null(z[[j]])){     if(is.vector(z[[j]])){       z[[j]] <- z[[j]][!is.na]     } else {       z[[j]] <- z[[j]][!is.na,]     }   }   x[[j]] <- x[[j]][!is.na,] }"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"data-exploration","dir":"Articles","previous_headings":"Application","what":"Data exploration","title":"Analysis code","text":"chunk performs exploratory data analysis. Requires: execution chunks setup, define_projects preprocess_data Execution time: \\(0.5\\) minutes Ensures: files explore_data.RData (results) info_explore.txt (session information) folder results chunk generates tables exploratory data analysis. Requires: execution chunk setup, file explore_data.RData folder results (generated chunk explore_apply) execution time: \\(1\\) second Ensures: files tab_cor.tex tab_auc.tex folder manuscript","code":"#<<setup>> #<<define_projects>> #<<preprocess_data>>  set.seed(1) alpha.holdout <- 0 alpha.crossval <- 1 family <- \"binomial\" nfolds <- 10 codes <- unlist(project) coef <- matrix(data=NA,nrow=ncol(x[[1]]),ncol=length(codes),dimnames=list(NULL,codes)) auc <- auc.pvalue <- matrix(data=NA,nrow=length(codes),ncol=length(codes),dimnames=list(codes,codes)) foldid <- make.folds.trans(y=y,family=\"binomial\",nfolds=nfolds)  ridge <- lasso <- list() for(i in seq_along(codes)){   ridge[[i]] <- glmnet::cv.glmnet(x=x[[codes[i]]],y=y[[codes[i]]],family=family,alpha=alpha.holdout,foldid=foldid[[i]])   coef[,i] <- stats::coef(ridge[[i]],s=\"lambda.min\")[-1]   for(j in seq_along(codes)){     if(i==j){       y_hat <- rep(x=NA,times=length(y[[i]]))       for(k in seq_len(nfolds)){         holdout <- foldid[[i]]==k         temp <- glmnet::cv.glmnet(x=x[[codes[i]]][!holdout,],y=y[[codes[i]]][!holdout],family=family,alpha=alpha.crossval)         y_hat[holdout] <- predict(object=temp,newx=x[[codes[i]]][holdout,],s=\"lambda.min\",type=\"response\")       }     } else {       y_hat <- as.numeric(predict(object=ridge[[i]],newx=x[[j]],s=\"lambda.min\",type=\"response\"))     }     auc[i,j] <- pROC::auc(response=y[[codes[j]]],predictor=y_hat,direction=\"<\",levels=c(0,1))     auc.pvalue[i,j] <- stats::wilcox.test(rank(y_hat)~y[[codes[[j]]]],alternative=\"less\",exact=FALSE)$p.value   } }  save(coef,auc,auc.pvalue,codes,file=file.path(path,\"results\",\"explore_data.RData\"))  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),       sessioninfo::session_info()),con=paste0(path,\"/results/info_explore.txt\")) #<<setup>> #if(any(unlist(project)!=names(refs))){stop(\"not compatible\")}  load(file.path(path,\"results/explore_data.RData\")) names <- gsub(pattern=\"IBD.|RA.\",replacement=\"\",x=names(unlist(project))) codes <- colnames(coef) cor.pvalue <- matrix(data=NA,nrow=length(codes),ncol=length(codes),dimnames=list(codes,codes)) for(i in seq_along(codes)){   for(j in seq_along(codes)){     cor.pvalue[i,j] <- stats::cor.test(x=coef[,i],y=coef[,j],method=\"spearman\",exact=FALSE)$p.value   } } diag(cor.pvalue) <- NA  insert.space <- function(table,cut){   index.left <- index.top <- seq_len(cut)   index.right <- index.bottom <- seq(from=cut+1,to=ncol(table))   top <- cbind(table[index.top,index.left],\"\",table[index.top,index.right])   bottom <- cbind(table[index.bottom,index.left],\"\",table[index.bottom,index.right])   out <- rbind(top,\"\",bottom)   colnames(out)[colnames(out)==\"\"] <- \" \"   return(out) }  table <- stats::cor(coef,method=\"spearman\") rownames(table) <- colnames(table) <- names black <- (!is.na(cor.pvalue)) & (cor.pvalue<=0.05) star <- (!is.na(cor.pvalue)) & (cor.pvalue<=0.05/choose(n=length(codes),k=2)) nonnegative <- table>=0 table <- format(round(table,digits=2),digits=2,trim=TRUE) table[nonnegative] <- paste0(\"\\\\phantom{-}\",table[nonnegative]) table[!black] <- paste0(\"\\\\textcolor{gray}{\",table[!black],\"}\") table[star] <- paste0(table[star],\"$^\\\\star$\") table[!star] <- paste0(table[!star],\"\\\\phantom{$^\\\\star$}\") #table[nonnegative] <- paste0(\"-\",table[nonnegative]) diag(table) <- \"-\" table <- insert.space(table=table,cut=5) xtable <- xtable::xtable(x=table,align=\"rccccccccc\",caption=\"Spearman correlation coefficients between the ridge regression coefficients from different datasets. Pairwise combinations of datasets with significantly correlated regression coefficients are highlighted, with black colour for nominal significance ($p$-value $\\\\leq 0.05$) and stars for adjusted significance ($p$-value $\\\\leq 0.05/28$). We expect a correlation coefficient close to $0$ for unrelated problems and close to $1$ for identical problems.\",label=\"tab_cor\") xtable::print.xtable(x=xtable,sanitize.text.function=identity,rotate.colnames=TRUE,caption.placement=\"top\",hline.after=c(0,nrow(table)),comment=FALSE,file=file.path(path,\"manuscript\",\"tab_cor.tex\")) #add.to.row=list(pos=list(5),command=\"\\\\hdashline \\n\")  table <- auc rownames(table) <- colnames(table) <- names table <- format(round(table,digits=2),digits=2) black <- auc.pvalue<=0.05 star <- auc.pvalue<=0.05/(length(codes)*length(codes)) diag(table) <- paste0(\"(\",diag(table),\")\") table[!black] <- paste0(\"\\\\textcolor{gray}{\",table[!black],\"}\") table[star] <- paste0(table[star],\"$^\\\\star$\") table[!star] <- paste0(table[!star],\"\\\\phantom{$^\\\\star$}\") table <- insert.space(table=table,cut=5) xtable <- xtable::xtable(x=table,align=\"rccccccccc\",caption=\"Out-of-sample area under the receiver operating characteristic curve (\\\\textsc{roc-auc}) from logistic ridge regression trained on the dataset in the row and tested on the dataset in the column (off-diagonal entries), or cross-validated \\\\textsc{roc-auc} from logistic lasso regression trained and tested on the same dataset by $10$-fold external cross-validation (diagonal entries, between brackets). The \\\\textsc{roc-auc} of a random classifier is $0.5$, while that of a perfect classifier is $1.0$. Entries on and off the diagonal are not comparable. Predictions that are significantly better than random predictions (according to the one-sided Mann-Whitney $U$ test for testing whether the ranks of the predicted probabilities are significantly higher for the cases than for the controls) are highlighted, with black colour for nominal significance ($p$-value $\\\\leq 0.05$) and stars for adjusted significance ($p$-value $\\\\leq 0.05/64$).\",label=\"tab_auc\") xtable::print.xtable(x=xtable,sanitize.text.function=identity,rotate.colnames=TRUE,caption.placement=\"top\",hline.after=c(0,nrow(table)),comment=FALSE,file=file.path(path,\"manuscript\",\"tab_auc.tex\"))"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"transfer-learning","dir":"Articles","previous_headings":"Application","what":"Transfer learning","title":"Analysis code","text":"chunk performs transfer learning analysis. Requires: execution chunks setup define_projects, file recount3_data.RData folder results (generated chunk download_data), execution chunk preprocess_data Execution time: 1.5 hours Ensures: application.RData (results) info_app.txt (session information) folder results chunk generates figure predictive performance. Requires: execution chunk setup, file application.RData folder results (generated chunk transfer_apply) Execution time: \\(1\\) second Ensures: file fig_app.eps folder manuscript chunk generates figure feature selection. Requires: execution chunk setup, file application.RData folder results (generated chunk transfer_apply) Execution time: \\(1\\) second Ensures: file fig_coef.eps folder manuscript","code":"#<<setup>> #<<define_projects>> #<<preprocess_data>>  alpha.init <- 0.95; type <- \"exp\"  result <- list() for(i in names(project)){   cat(\"project:\",i,\"\\n\")   result[[i]] <- list()   for(j in seq_len(5)){ # 5 repetitions of 10-fold CV     set.seed(j)     codes <- project[[i]]     result[[i]][[j]] <- crossval(y=y[codes],X=x[codes],family=\"binomial\",method=c(\"glm.separate\",\"glm.glmtrans\",\"sparselink\",\"glm.xrnet\"),nfolds=10,alpha=1,alpha.init=alpha.init,type=type,trial=FALSE)   } } save(result,project,file=file.path(path,\"results\",\"application.RData\"))  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),       sessioninfo::session_info()),con=paste0(path,\"/results/info_app.txt\")) #<<setup>>  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_app.eps\"),width=6.5,height=4) graphics::par(mfrow=c(2,1),mar=c(4,2,1,1),oma=c(0,0,0,0)) load(file.path(path,paste0(\"results/application.RData\")),verbose=TRUE)  #reference <- \"glm.glmtrans\" #experimental <- \"sparselink\"  model0 <- \"glm.glmtrans\" model1 <- \"sparselink\" model2 <- \"glm.xrnet\"  # predictivity metric <- lapply(result,function(x) do.call(what=\"rbind\",args=lapply(x,function(x) x$auc))) # DEV and AUC need different directions (increase=FALSE/TRUE)! metric <- do.call(what=\"rbind\",args=metric) metric <- metric/metric[,\"glm.separate\"] #xlab <- refs[rownames(metric)] #names <- gsub(pattern=\"\",replacement=\"\\n\",x=unlist(project))  label <- gsub(pattern=\"IBD.|RA.\",replacement=\"\",x=gsub(pattern=\" \",replacement=\"\\n\",x=names(unlist(project)))) index <- match(x=rownames(metric),table=unlist(project))  xlab <- label[index] change(x=xlab,y0=metric[,model0],y1=metric[,model1],y2=metric[,model2],main=\"metric\",increase=TRUE,cex.main=0.8) graphics::axis(side=1,at=length(project$IBD)+0.5,labels=\"|\",tick=FALSE,line=-0.25,font=2) graphics::abline(h=0.5,lty=2,col=\"grey\") graphics::abline(h=1,lty=2,col=\"grey\")  # sparsity nzero <- lapply(result,function(x) lapply(x,function(x) sapply(x$refit$coef,function(x) colSums(x!=0)))) nzero <- do.call(what=\"rbind\",args=do.call(what=\"c\",args=nzero)) change(x=xlab,y0=nzero[,model0],y1=nzero[,model1],y2=nzero[,model2],main=\"sparsity\",increase=FALSE,cex.main=0.8) graphics::axis(side=1,at=length(project$IBD)+0.5,labels=\"|\",tick=FALSE,line=-0.25,font=2) graphics::abline(h=0,lty=2,col=\"grey\") grDevices::dev.off()  # percentage change # (reported in section 4 \"application\" subsection 4.3 \"transfer learning\")  disease <- ifelse(rownames(metric) %in% project$IBD,\"IBD\",ifelse(rownames(metric) %in% project$RA,\"RA\",NA))  #round(100*colMeans(metric)-100,digits=2) round(100*colMeans(metric[disease==\"IBD\",])-100,digits=2) round(100*colMeans(metric[disease==\"RA\",])-100,digits=2)  colMeans(nzero) colMeans(nzero[disease==\"IBD\",]) colMeans(nzero[disease==\"RA\",])  #--- revision: report AUC --- Reduce(f=\"+\",x=lapply(result$IBD,function(x) x$auc))/length(result$IBD) lapply(result,function(x) round(colMeans(Reduce(f=\"+\",x=lapply(x,function(x) x$auc))/length(result$IBD)),digits=2)) #<<setup>>  load(file.path(path,\"results\",\"application.RData\"))  coefs <- list() for(i in seq_along(result$IBD)){   coefs[[i]] <- result$IBD[[i]]$refit$coef$sparselink   colnames(coefs[[i]]) <- names(project$IBD)   rownames(coefs[[i]]) <- rownames(result$IBD[[1]]$refit$coef$glm.glmtrans) # try to avoid this }  any <- rowSums(sapply(coefs,function(x) apply(x,1,function(x) any(x!=0))))!=0 for(i in seq_along(result$IBD)){   coefs[[i]] <- coefs[[i]][any,] } table <- Reduce(f=\"+\",x=coefs)/5  cex <- 0.7  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_coef.eps\"),width=7,height=4) graphics::par(mfrow=c(1,1),mar=c(2.5,4.5,0.5,1.5),oma=c(0,0,0,0)) graphics::plot.new() graphics::plot.window(xlim=c(0.6,ncol(table)+0.4),ylim=c(0.5,nrow(table)+0.5)) col <- apply(table,1,function(x) ifelse(all(x<=0),\"blue\",ifelse(all(x>=0),\"red\",\"black\"))) colnames <- gsub(x=colnames(table),pattern=\" \",replacement=\"\\n\") graphics::mtext(text=colnames,side=1,at=seq_len(ncol(table)),cex=cex,line=1) rownames <- rownames(table) graphics::mtext(text=rownames,side=2,at=seq_len(nrow(table)),las=2,cex=cex,line=0.7,col=col) star <- rowSums(table!=0)>1 graphics::mtext(text=\"*\",side=2,at=which(star),line=-0.3) graphics::mtext(text=ifelse(col==\"blue\",\"-\",ifelse(col==\"red\",\"+\",\".\")),side=4,at=seq_len(nrow(table)),las=2,cex=cex,line=0.5,col=col) for(i in seq_len(nrow(table))){   for(j in seq_len(ncol(table))){     for(k in 1:5){       col <- ifelse(coefs[[k]][i,j]<0,\"blue\",ifelse(coefs[[k]][i,j]>0,\"red\",\"white\"))       cex <- pmax(sqrt(5*abs(coefs[[k]][i,j])),0.2)       graphics::points(x=j-(-3+k)*0.17,y=i,col=col,cex=cex,pch=16)     }   } } graphics::abline(v=seq(from=0.5,to=5.5,by=1)) grDevices::dev.off()"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"data-based-simulation-under-development","dir":"Articles","previous_headings":"Application","what":"Data-based simulation (under development)","title":"Analysis code","text":"","code":"rm(list=ls()) path <- \"C:/Users/arauschenberger/Desktop/sparselink\" # LIH (Windows) #path <- \"/Users/armin.rauschenberger/Desktop/LIH/sparselink\" # LCSB (Mac)  dir <- c(\"results\",\"manuscript\",\"package/R/functions.R\") for(i in seq_along(dir)){   if(!dir.exists(file.path(path,dir[i]))&!file.exists(file.path(path,dir[i]))){     stop(paste0(\"Require folder/file'\",dir[i],\"'.\"))   }  } source(file.path(path,\"package/R/functions.R\")) # Or load 'sparselink' package.  inst <- rownames(utils::installed.packages()) pkgs <- c(\"knitr\",\"rmarkdown\",\"glmnet\",\"BiocManager\",\"mvtnorm\",\"glmtrans\",\"spls\",\"xrnet\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     utils::install.packages(pkgs[i])   } } pkgs <- c(\"recount3\",\"edgeR\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     BiocManager::install(pkgs[i])   } }  blue <- \"blue\"; red <- \"red\"  if(exists(\"sim.app\")&exists(\"fig.tab\")){   if(!sim.app&fig.tab){     files <- c(\"simulation_multiple.RData\",\"simulation_transfer.RData\",\"recount3_data.RData\",\"explore_data.RData\",\"application.RData\")     for(i in seq_along(files)){       if(!file.exists(file.path(path,\"results\",files[i]))){         stop(\"File\",files[i],\"is missing.\")       }     }   } } project <- list() project$IBD <- c(\"Tew (2016)\"=\"SRP063496\",                  \"Haberman (2019)\"=\"SRP129004\",                  \"Verstockt (2019)\"=\"ERP113396\",                  \"Verstockt (2020)\"=\"ERP114636\",                  \"Boyd (2018)\"=\"SRP100787\") project$RA <- c(\"Baker (2019)\"=\"SRP169062\",                 \"Moncrieffe (2017)\"=\"SRP074736\",                 \"Goldberg (2018)\"=\"SRP155483\") extra <- c(\"Lewis (2019)\"=\"ERP104864\") # https://doi.org/10.1016/j.celrep.2019.07.091 #<<setup>> #<<define_projects>>  load(file.path(path,\"results/recount3_data.RData\"))  #- - - - - - - - - - - - - - - #- - - extract features  - - -  #- - - - - - - - - - - - - - -  # extract features x <- list() for(i in c(unlist(project),extra)){   counts <- t(SummarizedExperiment::assays(data[[i]])$raw_counts)   colnames(counts) <- SummarizedExperiment::rowRanges(data[[i]])$gene_name   x[[i]] <- counts }  # select most expressed protein-coding genes (for all TL projects together) select <- list() total <- numeric() for(i in unlist(project)){   #total <- rbind(total,Matrix::colSums(x[[i]])) # original: mean filtering   total <- rbind(total,apply(X=x[[i]],MARGIN=2,FUN=stats::var)) # trial: variance filtering } type <- SummarizedExperiment::rowData(data[[i]])$gene_type cond <- type==\"protein_coding\" total[,!cond] <- 0 rank <- apply(X=total,MARGIN=1,FUN=rank) mean_rank <- rowMeans(rank) #temp <- cond & apply(total,2,function(x) all(x>0)) & (mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[2000]) # original: top 2000 temp <- cond & mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[5000] # trial: top 5000  for(i in unlist(project)){   select[[i]] <- temp }  # select most expressed protein-coding genes (for MTL project) #mean <- apply(X=x[[extra]],MARGIN=2,FUN=mean) # original var <- apply(X=x[[extra]],MARGIN=2,FUN=var) # trial #warning(\"change number in next line\") #temp <- cond & mean >= sort(mean[cond],decreasing=TRUE)[5000] # trial: top 5000 temp <- cond & var >= sort(var[cond],decreasing=TRUE)[5000] # trial: top 5000 select[[extra]] <- temp  # pre-processing for(i in c(unlist(project),extra)){   lib.size <- Matrix::rowSums(x[[i]])   x[[i]] <- x[[i]][,select[[i]],drop=FALSE]   norm.factors <- edgeR::calcNormFactors(object=t(x[[i]]),lib.size=lib.size)   gamma <- norm.factors*lib.size/mean(lib.size)   gamma <- matrix(data=gamma,nrow=nrow(x[[i]]),ncol=ncol(x[[i]]))   x[[i]] <- x[[i]]/gamma   x[[i]] <- 2*sqrt(x[[i]] + 3/8) # Anscombe transform   x[[i]] <- scale(x[[i]]) # scale because of different datasets!? }  #- - - - - - - - - - - - - - #- - - extract targets - - - #- - - - - - - - - - - - - -  # extract information on samples frame <- list() for(i in c(unlist(project),extra)){   list <- strsplit(data[[i]]$sra.sample_attributes,split=\"\\\\|\")   data[[i]]$sra.experiment_attributes   # What about sra.experiment_attributes?   n <- length(list)   cols <- unique(sapply(strsplit(unlist(list),split=\";;\"),function(x) x[1]))   ncol <- length(cols)   frame[[i]] <- matrix(data=NA,nrow=n,ncol=ncol,dimnames=list(rownames(x[[i]]),cols))   for(j in seq_len(n)){     for(k in seq_len(ncol)){       vector <- list[[j]]       which <- which(substring(text=vector,first=1,last=nchar(cols[k]))==cols[k])       string <- vector[which]       if(length(string)==0){next}       frame[[i]][j,k] <- strsplit(string,split=\";;\")[[1]][2]     }   }   frame[[i]] <- as.data.frame(frame[[i]]) }  # extract binary outcome y <- z <- list() for(i in unlist(project)){   # CONTINUE HERE!!!   if(i==\"ERP113396\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical history`,FUN=function(x) switch(EXPR=x,\"responder\"=1,\"non-responder\"=0,stop(\"invalid\")))   } else if(i==\"ERP114636\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical information`,FUN=function(x) switch(EXPR=x,\"response to vedolizumab therapy\"=1-1,\"no response to vedolizumab therapy\"=0+1,stop(\"invalid\")))     warning(\"Inverting response and non-response!\")   } else if(i==\"SRP100787\"){     y[[i]] <- sapply(X=frame[[i]]$condition,FUN=function(x) switch(EXPR=x,\"CD inactive\"=1,\"UC inactive\"=1,\"CD active\"=0,\"UC active\"=0,control=NA,\"NA\"=NA,stop(\"invalid\")))   } else if(i==\"SRP129004\"){     y[[i]] <- sapply(X=frame[[i]]$`week 4 remission`,FUN=function(x) switch(EXP=x,\"Yes\"=1,\"No\"=0,\"NA\"=NA,stop(\"invalid\")))     suppressWarnings(z[[i]] <- data.frame(pucai=as.numeric(frame[[i]]$pucai),mayo=as.numeric(frame[[i]]$`total mayo score`),histology=as.numeric(frame[[i]]$`histology severity score`)))   } else if(i==\"SRP063496\"){     y[[i]] <- sapply(X=frame[[i]]$`remission at week 10`,FUN=function(x) switch(x, \"Remitter\"=1,\"Non-remitter\"=0,\"N/A\"=NA,stop(\"invalid\")))   } else if(i==\"SRP169062\"){     y[[i]] <- sapply(X=frame[[i]]$`flare event`,FUN=function(x) switch(x,\"no flare\"=1,\"flare\"=0,stop(\"invalid\")))   } else if(i==\"SRP155483\"){     y[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=1,\"Low\"=0,\"Moderate\"=0,\"High\"=0,\"--\"=NA,stop(\"invalid\")))     z[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=0,\"Low\"=1,\"Moderate\"=2,\"High\"=3,\"--\"=NA,stop(\"invalid\")))   } else if(i==\"SRP074736\"){     y[[i]] <- sapply(X=frame[[i]]$`mtx response status`,FUN=function(x) switch(x,\"responder\"=1,\"non-responder\"=0,\"control\"=NA,stop(\"invalid\")))   } }  # overlap for(j in unlist(project)){   is.na <- is.na(y[[j]])   if(length(is.na)!=nrow(x[[j]])){stop()}   y[[j]] <- y[[j]][!is.na]   if(!is.null(z[[j]])){     if(is.vector(z[[j]])){       z[[j]] <- z[[j]][!is.na]     } else {       z[[j]] <- z[[j]][!is.na,]     }   }   x[[j]] <- x[[j]][!is.na,] } source(file.path(path,\"package/R/development.R\"))  x <- x$SRP100787 y <- y$SRP100787 sd <- apply(x,2,sd) # temporary # REMOVE THIS! x <- x[,sd>=sort(sd,decreasing=TRUE)[100]] # REMOVE THIS! iter <- 10 q <- 2 n <- nrow(x)  #-- -- --- --- #--- MTL --- #-- -- --- ---  prob_mtl <- c(0.00,0.05,0.10,0.15,0.20) auc_mtl <- list() for(i in seq_along(prob_mtl)){   auc_mtl[[i]] <- list()   for(j in seq_len(iter)){     Y <- matrix(data=NA,nrow=n,ncol=q)     for(k in seq_len(q)){       Y[,k] <- abs(y - stats::rbinom(n=n,size=1,prob=prob_mtl[i]))     }     #auc_mtl[[i]][[j]] <- cv.multiple(y=Y,X=x,method=c(\"glm.separate\",\"sparselink\"),family=\"binomial\",alpha.init=0.95,alpha=1,type=\"exp\",trial=FALSE)$auc     auc_mtl[[i]][[j]] <- joinet::cv.joinet(Y=Y,X=x,family=\"binomial\")   } } # MTL is beneficial under prob=0.15  # for joinet (deviance: lower=better) a <- sapply(auc_mtl,function(x) rowMeans(sapply(x,function(x) rowMeans(x)))) plot(prob_mtl,y=a[\"base\",],type=\"o\") lines(prob_mtl,y=a[\"meta\",],type=\"o\",lty=2)   #lapply(auc_mtl,function(x) rowMeans(sapply(x,function(x) colMeans(x))))  #--- --- --- --- #--- TL --- #--- --- --- ---  prob_tl <- c(0.3,0.4,0.5,0.6,0.7) auc_tl <- list() for(i in seq_along(prob_tl)){   auc_tl[[i]] <- list()   cond <- rep(x=NA,times=n)   Y <- X <- list()   for(j in seq_len(iter)){     n0 <- round(prob_tl[i]*sum(y==0))     n1 <- round(prob_tl[i]*sum(y==1))     cond[y==0] <- sample(rep(x=c(0,1),times=c(n0,sum(y==0)-n0))) #sample(rep(x=c(0,1),length.out=sum(y==0)))     cond[y==1] <- sample(rep(x=c(0,1),times=c(n1,sum(y==1)-n1))) #sample(rep(x=c(0,1),length.out=sum(y==1)))     Y <- list(y1=y[cond==0],y2=y[cond==1])     X <- list(x1=x[cond==0,],x2=x[cond==1,])     auc_tl[[i]][[j]] <- crossval(y=Y,X=X,method=c(\"glm.separate\",\"sparselink\"),family=\"binomial\",alpha.init=0.95,alpha=1,type=\"exp\",trial=FALSE)$auc   } }  save(prob_mtl,auc_mtl,prob_tl,auc_tl,file=file.path(path,\"results\",\"sim-devel.RData\"))  graphics::par(mfrow=c(1,2))  # MTL: AUC vs contamination aucs <- lapply(auc_mtl,function(x) sapply(x,function(x) colMeans(x))) auc <- sapply(aucs,function(x) rowMeans(x)) graphics::plot(x=prob_mtl,auc[\"sparselink\",],type=\"o\",ylim=c(0.4,0.8),col=\"blue\") graphics::lines(x=prob_mtl,auc[\"glm.separate\",],type=\"o\",col=\"red\") graphics::abline(h=0.5,lty=2,col=\"grey\")  # TL: source/target sample size aucs <- lapply(auc_tl,function(x) sapply(x,function(x) x[2,])) auc <- sapply(aucs,function(x) rowMeans(x)) graphics::plot(x=prob_tl,auc[\"sparselink\",],type=\"o\",ylim=c(0.4,0.8),col=\"blue\") graphics::lines(x=prob_tl,auc[\"glm.separate\",],type=\"o\",col=\"red\") graphics::abline(h=0.5,lty=2,col=\"grey\")  # statistical testing"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"multi-task-learning-under-development","dir":"Articles","previous_headings":"Application","what":"Multi-task learning (under development)","title":"Analysis code","text":"chunk saves session information generating figures tables.","code":"rm(list=ls()) path <- \"C:/Users/arauschenberger/Desktop/sparselink\" # LIH (Windows) #path <- \"/Users/armin.rauschenberger/Desktop/LIH/sparselink\" # LCSB (Mac)  dir <- c(\"results\",\"manuscript\",\"package/R/functions.R\") for(i in seq_along(dir)){   if(!dir.exists(file.path(path,dir[i]))&!file.exists(file.path(path,dir[i]))){     stop(paste0(\"Require folder/file'\",dir[i],\"'.\"))   }  } source(file.path(path,\"package/R/functions.R\")) # Or load 'sparselink' package.  inst <- rownames(utils::installed.packages()) pkgs <- c(\"knitr\",\"rmarkdown\",\"glmnet\",\"BiocManager\",\"mvtnorm\",\"glmtrans\",\"spls\",\"xrnet\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     utils::install.packages(pkgs[i])   } } pkgs <- c(\"recount3\",\"edgeR\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     BiocManager::install(pkgs[i])   } }  blue <- \"blue\"; red <- \"red\"  if(exists(\"sim.app\")&exists(\"fig.tab\")){   if(!sim.app&fig.tab){     files <- c(\"simulation_multiple.RData\",\"simulation_transfer.RData\",\"recount3_data.RData\",\"explore_data.RData\",\"application.RData\")     for(i in seq_along(files)){       if(!file.exists(file.path(path,\"results\",files[i]))){         stop(\"File\",files[i],\"is missing.\")       }     }   } } project <- list() project$IBD <- c(\"Tew (2016)\"=\"SRP063496\",                  \"Haberman (2019)\"=\"SRP129004\",                  \"Verstockt (2019)\"=\"ERP113396\",                  \"Verstockt (2020)\"=\"ERP114636\",                  \"Boyd (2018)\"=\"SRP100787\") project$RA <- c(\"Baker (2019)\"=\"SRP169062\",                 \"Moncrieffe (2017)\"=\"SRP074736\",                 \"Goldberg (2018)\"=\"SRP155483\") extra <- c(\"Lewis (2019)\"=\"ERP104864\") # https://doi.org/10.1016/j.celrep.2019.07.091 #<<setup>> #<<define_projects>>  load(file.path(path,\"results/recount3_data.RData\"))  #- - - - - - - - - - - - - - - #- - - extract features  - - -  #- - - - - - - - - - - - - - -  # extract features x <- list() for(i in c(unlist(project),extra)){   counts <- t(SummarizedExperiment::assays(data[[i]])$raw_counts)   colnames(counts) <- SummarizedExperiment::rowRanges(data[[i]])$gene_name   x[[i]] <- counts }  # select most expressed protein-coding genes (for all TL projects together) select <- list() total <- numeric() for(i in unlist(project)){   #total <- rbind(total,Matrix::colSums(x[[i]])) # original: mean filtering   total <- rbind(total,apply(X=x[[i]],MARGIN=2,FUN=stats::var)) # trial: variance filtering } type <- SummarizedExperiment::rowData(data[[i]])$gene_type cond <- type==\"protein_coding\" total[,!cond] <- 0 rank <- apply(X=total,MARGIN=1,FUN=rank) mean_rank <- rowMeans(rank) #temp <- cond & apply(total,2,function(x) all(x>0)) & (mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[2000]) # original: top 2000 temp <- cond & mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[5000] # trial: top 5000  for(i in unlist(project)){   select[[i]] <- temp }  # select most expressed protein-coding genes (for MTL project) #mean <- apply(X=x[[extra]],MARGIN=2,FUN=mean) # original var <- apply(X=x[[extra]],MARGIN=2,FUN=var) # trial #warning(\"change number in next line\") #temp <- cond & mean >= sort(mean[cond],decreasing=TRUE)[5000] # trial: top 5000 temp <- cond & var >= sort(var[cond],decreasing=TRUE)[5000] # trial: top 5000 select[[extra]] <- temp  # pre-processing for(i in c(unlist(project),extra)){   lib.size <- Matrix::rowSums(x[[i]])   x[[i]] <- x[[i]][,select[[i]],drop=FALSE]   norm.factors <- edgeR::calcNormFactors(object=t(x[[i]]),lib.size=lib.size)   gamma <- norm.factors*lib.size/mean(lib.size)   gamma <- matrix(data=gamma,nrow=nrow(x[[i]]),ncol=ncol(x[[i]]))   x[[i]] <- x[[i]]/gamma   x[[i]] <- 2*sqrt(x[[i]] + 3/8) # Anscombe transform   x[[i]] <- scale(x[[i]]) # scale because of different datasets!? }  #- - - - - - - - - - - - - - #- - - extract targets - - - #- - - - - - - - - - - - - -  # extract information on samples frame <- list() for(i in c(unlist(project),extra)){   list <- strsplit(data[[i]]$sra.sample_attributes,split=\"\\\\|\")   data[[i]]$sra.experiment_attributes   # What about sra.experiment_attributes?   n <- length(list)   cols <- unique(sapply(strsplit(unlist(list),split=\";;\"),function(x) x[1]))   ncol <- length(cols)   frame[[i]] <- matrix(data=NA,nrow=n,ncol=ncol,dimnames=list(rownames(x[[i]]),cols))   for(j in seq_len(n)){     for(k in seq_len(ncol)){       vector <- list[[j]]       which <- which(substring(text=vector,first=1,last=nchar(cols[k]))==cols[k])       string <- vector[which]       if(length(string)==0){next}       frame[[i]][j,k] <- strsplit(string,split=\";;\")[[1]][2]     }   }   frame[[i]] <- as.data.frame(frame[[i]]) }  # extract binary outcome y <- z <- list() for(i in unlist(project)){   # CONTINUE HERE!!!   if(i==\"ERP113396\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical history`,FUN=function(x) switch(EXPR=x,\"responder\"=1,\"non-responder\"=0,stop(\"invalid\")))   } else if(i==\"ERP114636\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical information`,FUN=function(x) switch(EXPR=x,\"response to vedolizumab therapy\"=1-1,\"no response to vedolizumab therapy\"=0+1,stop(\"invalid\")))     warning(\"Inverting response and non-response!\")   } else if(i==\"SRP100787\"){     y[[i]] <- sapply(X=frame[[i]]$condition,FUN=function(x) switch(EXPR=x,\"CD inactive\"=1,\"UC inactive\"=1,\"CD active\"=0,\"UC active\"=0,control=NA,\"NA\"=NA,stop(\"invalid\")))   } else if(i==\"SRP129004\"){     y[[i]] <- sapply(X=frame[[i]]$`week 4 remission`,FUN=function(x) switch(EXP=x,\"Yes\"=1,\"No\"=0,\"NA\"=NA,stop(\"invalid\")))     suppressWarnings(z[[i]] <- data.frame(pucai=as.numeric(frame[[i]]$pucai),mayo=as.numeric(frame[[i]]$`total mayo score`),histology=as.numeric(frame[[i]]$`histology severity score`)))   } else if(i==\"SRP063496\"){     y[[i]] <- sapply(X=frame[[i]]$`remission at week 10`,FUN=function(x) switch(x, \"Remitter\"=1,\"Non-remitter\"=0,\"N/A\"=NA,stop(\"invalid\")))   } else if(i==\"SRP169062\"){     y[[i]] <- sapply(X=frame[[i]]$`flare event`,FUN=function(x) switch(x,\"no flare\"=1,\"flare\"=0,stop(\"invalid\")))   } else if(i==\"SRP155483\"){     y[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=1,\"Low\"=0,\"Moderate\"=0,\"High\"=0,\"--\"=NA,stop(\"invalid\")))     z[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=0,\"Low\"=1,\"Moderate\"=2,\"High\"=3,\"--\"=NA,stop(\"invalid\")))   } else if(i==\"SRP074736\"){     y[[i]] <- sapply(X=frame[[i]]$`mtx response status`,FUN=function(x) switch(x,\"responder\"=1,\"non-responder\"=0,\"control\"=NA,stop(\"invalid\")))   } }  # overlap for(j in unlist(project)){   is.na <- is.na(y[[j]])   if(length(is.na)!=nrow(x[[j]])){stop()}   y[[j]] <- y[[j]][!is.na]   if(!is.null(z[[j]])){     if(is.vector(z[[j]])){       z[[j]] <- z[[j]][!is.na]     } else {       z[[j]] <- z[[j]][!is.na,]     }   }   x[[j]] <- x[[j]][!is.na,] } source(file.path(path,\"package/R/development.R\"))  #- - - - - - - - - -  #- - prepare data - - #- - - - - - - - - -   # explore SRP048801  project <- \"ERP104864\" if(project==\"SRP155483\"){   X <- x$SRP155483   vars <- c(\"disease activity\",\"das score\")   Y <- frame$SRP155483[,vars]   sapply(unique(Y$`disease activity`),function(x) range(as.numeric(Y$`das score`[Y$`disease activity`==x])))   warning(\"DAS score defines disease activity!\")   problem <- list()   problem$unique <- colnames(Y) } else if(project==\"SRP129004\"){   X <- x$SRP129004   vars <- c(\"histology severity score\",\"total mayo score\")   Y <- frame$SRP129004[,vars]   names <- intersect(rownames(X),rownames(Y))   X <- X[names,]   Y <- Y[names,]   cond <- frame$SRP129004[names,\"diagnosis\"]==\"Ulcerative Colitis\"   X <- X[cond,]   Y <- Y[cond,]   problem <- list()   problem$unique <- colnames(Y) } else if(project==\"ERP104864\"){   X <- x$ERP104864   vars <- c(\"CCP\",\"CRP\",\"crp\",\"DAS28\",\"ESR\",\"esr\",\"HAQ\",\"VAS\",\"SWOLLEN\",\"TENDER\") # \"inflammatory score\" dropped due to NA # \"RF\" dropped because binary   Y <- frame$ERP104864[,vars]   pathotype <- frame$ERP104864$pathotype   if(any(rownames(X)!=rownames(Y))){stop()}   #Y <- Y[Y$pathotype==\"lymphoid\",vars]   if(any(!is.na(Y$CRP)&!is.na(Y$crp))){     stop(\"Invalid.\")   } else {     Y$CRP[is.na(Y$CRP)] <- Y$crp[is.na(Y$CRP)]     Y$crp <- NULL   }   if(any(!is.na(Y$ESR)&!is.na(Y$esr))){     stop(\"Invalid.\")   } else {     Y$ESR[is.na(Y$ESR)] <- Y$esr[is.na(Y$ESR)]     Y$esr <- NULL   }   problem <- list()   #problem$joint <- c(\"SWOLLEN\",\"TENDER\")   #problem$proms <- c(\"VAS\",\"HAQ\")   #problem$labor <- c(\"CRP\",\"ESR\") # CCP might be too different (check cor)   problem$trial <- c(\"CRP\",\"ESR\",\"SWOLLEN\")   #problem$trial <- c(\"DAS28\",\"SWOLLEN\",\"TENDER\")   #problem$all <- colnames(y) }  for(i in seq_len(ncol(Y))){   class(Y[[i]]) <- \"numeric\" }  cond <- apply(X=Y,MARGIN=1,FUN=function(x) all(!is.na(x))) #& pathotype==\"lymphoid\" # subtypes seem to be defined based on clinical scores #Y <- as.matrix(Y)[cond,] # temporary: binarisation y <- scale(as.matrix(Y)[cond,]) x <- X[cond,]  #- - - - - - - - - - - - -  #- - explore similarity - - #- - - - - - - - - - - - -   cor <- stats::cor(y,use=\"pairwise.complete.obs\",method=\"spearman\") round(x=cor,digits=2) graphics::image(t(cor)[,ncol(cor):1]) #stats::heatmap(x=as.matrix(Y),Rowv=NA) d <- stats::dist(x=t(Y)) hclust <- stats::hclust(d=d) graphics::plot(hclust)  graphics::par(mfrow=c(2,4),mar=c(2,2,1,1)) for(i in seq_len(ncol(y))){     pvalue <- apply(x,2,function(x) cor.test(x,y[,i],method=\"spearman\")$p.value)     graphics::hist(x=pvalue,main=colnames(y)[i]) }  #--- relationship between cor coef and cor p-value --- coef <- stats::cor(y=y[,\"CRP\"],x=x,method=\"spearman\") pval <- apply(X=x,MARGIN=2,FUN=function(x) stats::cor.test(x=x,y=y[,\"CRP\"],method=\"spearman\")$p.value) graphics::plot(x=coef,y=sign(coef)*(-log10(pval))^0.5) #--- conclusion: equivalent ---  #--- examine correlation between ridge coefficients --- coef <- matrix(data=NA,nrow=ncol(x),ncol=ncol(y),dimnames=list(NULL,colnames(y))) for(i in seq_len(ncol(y))){   object <- glmnet::cv.glmnet(x=x,y=y[,i],family=\"gaussian\",alpha=0)   coef[,i] <- stats::coef(object=object,s=\"lambda.min\")[-1] } round(stats::cor(coef,method=\"spearman\"),digits=2) #--- conclusion: some sets are strongly correlated ---  #cor(rowSums(scale(Y)),Y,method=\"spearman\")  #- - - - - - - - - - - - -  #- - cross-validation - - #- - - - - - - - - - - - -   alpha.init <- 0.95; alpha <- 1; type <- \"exp\"; trial <- FALSE #alpha.init <- NA; alpha <- 1; type <- \"exp\"; trial <- TRUE results <- list() for(k in seq_along(problem)){   results[[k]] <- list()   for(i in seq_len(3)){ # 5 repetitions of 10-fold CV     set.seed(i)     method <- c(\"glm.empty\",\"glm.separate\",\"glm.mgaussian\",\"sparselink\",\"glm.spls\") #\"sparselink\" \"group.devel\"     results[[k]][[i]] <-  cv.multiple(y=y[,problem[[k]]],X=x,family=\"gaussian\",method=method,nfolds=10,alpha=alpha,alpha.init=alpha.init,type=type,trial=trial)   } }  save(results,file=file.path(path,\"results\",\"app_mtl_devel.RData\"))  lapply(results,function(x) lapply(x,function(x) colMeans(x$deviance)))   colMeans(results[[1]][[1]]$deviance/results[[1]][[1]]$deviance[,\"glm.empty\"]) names(results) <- names(problem)  colMeans(results$trial[[1]]$deviance/results$trial[[1]]$deviance[,\"glm.empty\"])  lapply(results,function(x) rowMeans(sapply(x,function(x) rowMeans(apply(x$deviance,1,rank)))))  object <- devel(y=y[,problem$trial],x=x,family=\"gaussian\")  cm <- numeric() for(k in seq_along(problem)){   for(i in seq_len(1)){     dev <- results[[k]][[i]]$deviance     temp <- colMeans(dev/dev[,\"glm.separate\"])     cm <- rbind(cm,temp)     #cat(cm,\"\\n\")   } } colMeans(cm)  # separate, mgaussian, sparselink and devel have similar performance (i.e., MTL has no benefit with any of these three approaches), examine whether other approaches are better  # examine whether group lasso for TL/MTL performs better  # Consider using different candidate values, e.g., 0.01,0.5,1,1.5,2,10 also for sparselink. Removing 0 might be a good choice. (If 0 is not included, however, initial ridge regression might be better.)  #- - - - - - - - - - - - #- - learning curve - - #- - - - - - - - - - - -  size <- unique(c(seq(from=50,to=nrow(x),by=25),nrow(x))) iter <- 10 # increase to 10 size <- nrow(x) # suppress learning curve  metric <- list() setting <- expand.grid(problem=names(problem),size=size,iter=seq_len(iter)) for(i in seq_len(nrow(setting))){   cat(progress=paste0(100*i/nrow(setting),\"%\"),\"\\n\")   cond <- sample(x=rep(x=c(FALSE,TRUE),times=c(nrow(x)-setting$size[i],setting$size[i])))   vars <- problem[[setting$problem[i]]]   metric[[i]] <- joinet:::cv.joinet(Y=y[cond,vars],X=x[cond,],family=\"gaussian\",compare=\"mnorm\")   #method <- c(\"glm.empty\",\"glm.separate\",\"glm.mgaussian\",\"sparselink\")   #metric[[i]] <-  cv.multiple(y=y[cond,vars],X=x[cond,],family=\"gaussian\",method=method,nfolds=10,alpha.init=0.95,alpha=1,type=\"exp\",trial=FALSE) } frac <- sapply(X=metric,FUN=function(x) colMeans(t(x)/x[\"none\",]))  #frac <- sapply(X=metric,FUN=function(x) colMeans(x$deviance/x$deviance[,\"glm.empty\"]))  graphics::par(mfrow=c(1,length(problem)),mar=c(3,3,2,0.5)) for(i in seq_along(problem)){   graphics::plot.new()   graphics::plot.window(xlim=range(size),ylim=range(frac))   graphics::box()   graphics::title(main=names(problem)[i])   graphics::axis(side=1)   graphics::axis(side=2)   graphics::abline(h=1,col=\"grey\",lty=2)   cond <- setting$problem==names(problem)[i]   col <- c(base=\"red\",mnorm=\"orange\",meta=\"blue\")   #col <- c(glm.separate=\"red\",sparselink=\"blue\")   for(j in names(col)){     val <- tapply(X=frac[j,cond],INDEX=setting$size[cond],FUN=mean)     graphics::points(x=setting$size[cond],y=frac[j,cond],col=col[j])     graphics::lines(x=size,y=val,col=col[j],type=\"o\",pch=16)   } }  #  JOINET is better than standard lasso when n>=100, performance is similar to spls and better than glmnet-mgaussian   #--- --- --- --- --- --- # binarisation --- #--- --- --- --- --- ---   yy <- 1*cbind(y[,\"CCP\"]>20,y[,\"CRP\"]>10,y[,\"DAS28\"]>5) metric <- list() for(i in 1:10){   metric[[i]] <- joinet:::cv.joinet(Y=yy,X=x,family=\"binomial\") }  #rowMeans(sapply(metric,function(x) rowMeans(x)))  #--- --- --- --- --- --- --- #--- explore other datasets --- #--- --- --- --- --- --- ---  #projects <- recount3::available_projects(organism=\"human\") #recount3::read_metadata()   #data <- xlsx::read.xlsx(paste0(path,\"/results/PPMI_Curated_Data_Cut_Public_20250321.xlsx\"),sheetIndex=1) data <- read.csv(paste0(path,\"/results/PPMI_Curated_Data_Cut_Public_20250321.csv\"))  # baseline data (predictors) x <- data[data$COHORT==1 & data$EVENT_ID==\"BL\",] rownames(x) <- x$PATNO prop.miss <- colMeans(is.na(x)) x <- x[,prop.miss<=0.5 & sapply(x,class) %in% c(\"numeric\",\"integer\")] x <- x[,which(colnames(x)==\"age\"):ncol(x)] x <- missRanger::missRanger(data=x,pmm.k=3,num.trees=100,verbose=0,seed=1) x <- scale(x)  # follow-up data (outcomes) visit <- c(\"V04\",\"V06\",\"V08\") y <- data[data$COHORT==1 & data$EVENT_ID %in% visit,] colnames(y)[colnames(y)==\"updrs_totscore\"] <- \"updrs\" vars <- c(\"moca\",\"quip\",\"updrs\",\"gds\",\"scopa\",\"ess\",\"bjlot\",\"rem\") y <- y[,c(\"EVENT_ID\",\"PATNO\",vars)] y <- reshape(data=y,idvar=\"PATNO\",timevar=\"EVENT_ID\",direction=\"wide\") rownames(y) <- y$PATNO; y$PATNO <- NULL  # overlap names <- intersect(rownames(x),rownames(y)) x <- x[names,] y <- y[names,] y <- as.matrix(y) #y <- scale(y)  metric <- list() for(i in seq_along(vars)){   cat(vars[i],\"\\n\")   cols <- paste0(vars[i],\".\",visit)   cond <- rowSums(is.na(y[,cols]))==0 # temporary   if(sum(cond)>250){cond[cumsum(cond)>250] <- FALSE} # temporary   metric[[i]] <- joinet:::cv.joinet(Y=y[cond,cols],X=x[cond,],family=\"gaussian\",compare=\"mnorm\")   #method <- c(\"glm.empty\",\"glm.separate\",\"glm.mgaussian\",\"sparselink\",\"devel\") # ,\"sparselink\")   #metric[[i]] <- cv.multiple(y=y[cond,cols],X=x[cond,],family=\"gaussian\",method=method,nfolds=10,alpha.init=0.95,alpha=1,type=\"exp\",trial=FALSE) }  #rowMeans(sapply(metric,function(x) colMeans(t(x)/x[\"none\",]))) rowMeans(sapply(metric,function(x) colMeans(x$deviance/x$deviance[,\"glm.empty\"])))"},{"path":"https://rauschenberger.github.io/sparselink/articles/article.html","id":"estimating-sparse-regression-models-in-multi-task-learning-and-transfer-learning-through-adaptive-penalisation","dir":"Articles","previous_headings":"","what":"Estimating sparse regression models in multi-task learning and transfer learning through adaptive penalisation","title":"Sparse regression for related problems","text":"Armin Rauschenberger\\(~^{1,2,*}\\) , Petr V. Nazarov\\(~^{1,\\dagger}\\) , Enrico Glaab\\(~^{2,\\dagger}\\) \\(^1\\)Bioinformatics Artificial Intelligence, Department Medical Informatics, Luxembourg Institute Health (LIH), Strassen, Luxembourg. \\(^2\\)Biomedical Data Science, Luxembourg Centre Systems Biomedicine (LCSB), University Luxembourg, Esch-sur-Alzette, Luxembourg. \\(^{*}\\)correspondence addressed. \\(^{\\dagger}\\)Petr V. Nazarov Enrico Glaab share senior authorship.","code":""},{"path":"https://rauschenberger.github.io/sparselink/articles/article.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"Sparse regression for related problems","text":"propose simple two-stage procedure sharing information related high-dimensional prediction classification problems. stages, perform sparse regression separately problem. done without prior information first stage, use coefficients first stage prior information second stage. Specifically, designed feature-specific sign-specific adaptive weights share information feature selection, effect directions effect sizes different problems. proposed approach applicable multi-task learning well transfer learning. provides sparse models (.e., non-zero coefficients problem) easy interpret. show simulation application tends select fewer features achieving similar predictive performance compared available methods. implementation available R package ‘sparselink’ (https://github.com/rauschenberger/sparselink).","code":""},{"path":"https://rauschenberger.github.io/sparselink/articles/article.html","id":"full-text","dir":"Articles","previous_headings":"","what":"Full text","title":"Sparse regression for related problems","text":"Rauschenberger et al. (2025). “Estimating sparse regression models multi-task learning transfer learning adaptive penalisation”. Manuscript preparation. (Available ORBilu.)","code":""},{"path":"https://rauschenberger.github.io/sparselink/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Armin Rauschenberger. Author, maintainer.","code":""},{"path":"https://rauschenberger.github.io/sparselink/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Armin Rauschenberger, Petr V. Nazarov, Enrico Glaab (2024). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". Manuscript preparation","code":"@Article{,   title = {Estimating sparse regression models in multi-task learning and transfer learning through adaptive penalisation},   author = {Armin Rauschenberger and Petr V. Nazarov and Enrico Glaab},   journal = {Manuscript in preparation},   year = {2024},   volume = {X},   number = {X},   pages = {X},   doi = {X}, }"},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"sparse-regression-for-related-problems","dir":"","previous_headings":"","what":"Sparse regression for related problems","title":"Sparse regression for related problems","text":"Estimates sparse regression models (.e., non-zero coefficients) high-dimensional multi-task learning transfer learning settings","code":""},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Sparse regression for related problems","text":"Install current release CRAN: latest development version GitHub: repository mirrored two institutional GitLab instances (see LIH LCSB).","code":"#install.packages(\"sparselink\") # not yet available #install.packages(\"remotes\") remotes::install_github(\"rauschenberger/sparselink\")"},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"reference","dir":"","previous_headings":"","what":"Reference","title":"Sparse regression for related problems","text":"Armin Rauschenberger , Petr V. Nazarov , Enrico Glaab  (2025). “Estimating sparse regression models multi-task learning transfer learning adaptive penalisation”. Manuscript preparation.","code":""},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"reproducibility","dir":"","previous_headings":"","what":"Reproducibility","title":"Sparse regression for related problems","text":"code reproducing simulations applications shown manuscript available vignette (analysis). installing package remotes::install_github(\"rauschenberger/sparselink\",build_vignettes=TRUE) restarting R, vignette can also loaded vignette(topic=\"analysis\",package=\"sparselink\").","code":""},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Sparse regression for related problems","text":"R package sparselink implements sparse regression related problems (Rauschenberger et al., 2025). Copyright © 2025 Armin Rauschenberger; Luxembourg Institute Health (LIH), Department Medical Informatics (DMI), Bioinformatics Artificial Intelligence (BioAI); University Luxembourg, Luxembourg Centre Systems Biomedicine (LCSB), Biomedical Data Science (BDS) Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/calc.metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate deviance — calc.metric","title":"Calculate deviance — calc.metric","text":"Calculates Gaussian deviance (mean-squared error) binomial deviance.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/calc.metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate deviance — calc.metric","text":"","code":"calc.metric(y, y_hat, family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/calc.metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate deviance — calc.metric","text":"y response y_hat predictor family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/calc.metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate deviance — calc.metric","text":"","code":"n <- 100 family <- \"gaussian\" y <- stats::rnorm(n=n) y_hat <- stats::rnorm(n=n) calc.metric(y=y,y_hat=y_hat,family=family) #> [1] 2.170289  family <- \"binomial\" y <- stats::rbinom(n=n,size=1,prob=0.5) y_hat <- stats::runif(n=n) calc.metric(y=y,y_hat=y_hat,family=family) #> [1] 0.9851105"},{"path":"https://rauschenberger.github.io/sparselink/reference/change.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot pairwise differences — change","title":"Plot pairwise differences — change","text":"Plot pairwise differences","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/change.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot pairwise differences — change","text":"","code":"change(   x,   y0,   y1,   y2,   dist = 0.15,   main = \"\",   cex.axis = 0.5,   cex.main = 1,   increase = TRUE )"},{"path":"https://rauschenberger.github.io/sparselink/reference/change.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot pairwise differences — change","text":"x setting: character vector y0 values left: numeric vector y1 values centre: numeric vector y2 values right: numeric vector dist horizontal distance points main title cex.axis numeric cex.main numeric increase change arrow NULL, , ","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Coefficients — coef.sparselink","title":"Extract Coefficients — coef.sparselink","text":"Extracts coefficients object class [sparselink].","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Coefficients — coef.sparselink","text":"","code":"# S3 method for class 'sparselink' coef(object)"},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Coefficients — coef.sparselink","text":"object object class `sparselink`","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Coefficients — coef.sparselink","text":"Returns estimated coefficients. output list two slots: slot `alpha` estimated intercept (vector length \\(q\\)), slot `beta` estimated slopes (matrix \\(p\\) rows \\(q\\) columns).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract Coefficients — coef.sparselink","text":"Armin Rauschenberger, Petr N. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision. https://hdl.handle.net/10993/63425","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Coefficients — coef.sparselink","text":"","code":"family <- \"gaussian\" data <- sim.data.transfer(family=family) #data <- sim.data.multiple(family=family) object <- sparselink(x=data$X_train,y=data$y_train,family=family) #> alpha.init=0.95, alpha=1, trial=FALSE, type=exp #> mode: transfer learning coef <- coef(object=object)"},{"path":"https://rauschenberger.github.io/sparselink/reference/comb_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract internal and external weights — comb_split","title":"Extract internal and external weights — comb_split","text":"Extract internal external weights","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/comb_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract internal and external weights — comb_split","text":"","code":"comb_split(coef, id)"},{"path":"https://rauschenberger.github.io/sparselink/reference/comb_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract internal and external weights — comb_split","text":"coef matrix \\(p\\) rows (features) \\(q\\) columns (problems) id integer \\(1,\\ldots,q\\)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/comb_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract internal and external weights — comb_split","text":"Returns list slots lower.limits, upper.limits, weight.source (external weights) weight.target (internal weights). slot vector length \\(2*p\\), first \\(p\\) entries positive effects last \\(p\\) entries negative effects.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/comb_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract internal and external weights — comb_split","text":"","code":"p <- 10 q <- 3 data <- stats::rbinom(p*q,size=1,prob=0.2)*stats::rnorm(p*q) coef <- matrix(data=data,nrow=p,ncol=q) comb_split(coef=coef,id=1) #> $lower.limits #>  [1]    0    0    0    0    0    0    0    0    0    0 -Inf -Inf -Inf -Inf -Inf #> [16] -Inf -Inf -Inf -Inf -Inf #>  #> $upper.limits #>  [1] Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf   0   0   0   0   0   0   0   0   0 #> [20]   0 #>  #> $weight.source #>  [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>  [8] 0.0000000 1.5092707 0.0000000 0.0000000 0.0000000 0.0000000 0.3451972 #> [15] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>  #> $weight.target #>  [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>  [8] 0.0000000 0.0000000 0.0000000 0.4260198 0.0000000 0.0000000 0.0000000 #> [15] 0.6664857 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>"},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_pf.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct penalty factors — construct_pf","title":"Construct penalty factors — construct_pf","text":"Uses internal external weights (negative positive effects) well internal external exponents/factors weights construct penalty factors.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_pf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct penalty factors — construct_pf","text":"","code":"construct_pf(w_int, w_ext, v_int, v_ext, type)"},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_pf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct penalty factors — construct_pf","text":"w_int internal weights: numeric vector length p non-negative entries w_ext external weights: numeric vector length p non-negative entries v_int exponent factor internal weights: non-negative scalar v_ext exponent factor external weights: non-negative scalar type character \"geo\", \"exp\", \"rem\" \"ari\" (without addition \".con\")","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/count_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Metrics for sign detection — count_matrix","title":"Metrics for sign detection — count_matrix","text":"Metrics sign detection","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/count_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metrics for sign detection — count_matrix","text":"","code":"count_matrix(truth, estim)"},{"path":"https://rauschenberger.github.io/sparselink/reference/count_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metrics for sign detection — count_matrix","text":"truth n times p matrix entries -1, 0, 1 estim n times p matrix entries -1, 0, 1","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Metrics for sign detection — count_vector","title":"Metrics for sign detection — count_vector","text":"Metrics sign detection","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metrics for sign detection — count_vector","text":"","code":"count_vector(truth, estim)"},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metrics for sign detection — count_vector","text":"truth vector length p entries -1, 0, 1 estim vector length p entries -1, 0, 1","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse.data.html","id":null,"dir":"Reference","previous_headings":"","what":"Data fusion — fuse.data","title":"Data fusion — fuse.data","text":"Data fusion","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse.data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data fusion — fuse.data","text":"","code":"fuse.data(x, y = NULL, foldid = NULL)"},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse.data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data fusion — fuse.data","text":"x list \\(q\\) matrices, \\(n_1,\\ldots,n_q\\) rows \\(p\\) columns y list \\(q\\) vectors, length \\(n_1,\\ldots,n_q\\), NULL (default) foldid list \\(q\\) vectors, length \\(n_1,\\ldots,n_q\\), NULL (default)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse.data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data fusion — fuse.data","text":"","code":"data <- sim.data.transfer() sapply(X=data$y_train,FUN=length) #> [1]  50 100 200 sapply(X=data$X_train,FUN=dim) #>      [,1] [,2] [,3] #> [1,]   50  100  200 #> [2,]  200  200  200 fuse <- fuse.data(x=data$X_train,y=data$y_train) length(fuse$y) #> [1] 350 dim(fuse$x) #> [1] 350 200 table(fuse$index) #>  #>   1   2   3  #>  50 100 200"},{"path":"https://rauschenberger.github.io/sparselink/reference/get.info.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract dimensionality. — get.info","title":"Extract dimensionality. — get.info","text":"Extract dimensionality.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/get.info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract dimensionality. — get.info","text":"","code":"get.info(x, y)"},{"path":"https://rauschenberger.github.io/sparselink/reference/get.info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract dimensionality. — get.info","text":"x list \\(q\\) matrices, \\(n_k\\) (samples) rows \\(p\\) columns (features), \\(k\\) \\(1,\\ldots,q\\) y list \\(q\\) vectors, \\(n_k\\) entries, \\(k\\) \\(1,\\ldots,q\\)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/get.info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract dimensionality. — get.info","text":"Returns list slots \\(q\\) (scalar, number problems), \\(n\\) (vector length \\(q\\), number samples) \\(p\\) (scalar, number features)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/get.info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract dimensionality. — get.info","text":"","code":"data <- sim.data.transfer() get.info(x=data$X_train,y=data$y_train) #> $q #> [1] 3 #>  #> $n #> [1]  50 100 200 #>  #> $p #> [1] 200 #>"},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Link function — link_function","title":"Link function — link_function","text":"Applies link function.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Link function — link_function","text":"","code":"link_function(mu, family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Link function — link_function","text":"mu numeric vector (values unit interval family=\"binomial\") family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Link function — link_function","text":"","code":"family <- \"binomial\" from <- ifelse(family==\"binomial\",0,-3) to <- ifelse(family==\"binomial\",1,3) mu <- seq(from=from,to=to,length.out=100) eta <- link_function(mu=mu,family=family) graphics::plot(x=mu,y=eta,type=\"l\",main=family) v <- ifelse(family==\"binomial\",0.5,0) graphics::abline(v=v,lty=2) graphics::abline(h=0,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"logit function — logit","title":"logit function — logit","text":"logit function","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logit function — logit","text":"","code":"logit(x)"},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logit function — logit","text":"x numeric vector values unit interval","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"logit function — logit","text":"","code":"x <- seq(from=0,to=1,length.out=100) y <- logit(x=x) graphics::plot(x=x,y=y,type=\"l\") graphics::abline(v=0.5,lty=2) graphics::abline(h=0,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Folds for multi-task learning — make.folds.multi","title":"Folds for multi-task learning — make.folds.multi","text":"Folds multi-task learning","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Folds for multi-task learning — make.folds.multi","text":"","code":"make.folds.multi(y, family, nfolds = 10)"},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Folds for multi-task learning — make.folds.multi","text":"y matrix n rows (samples) q columns (outcomes) family character \"gaussian\" \"binomial\" nfolds integer 2 n","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Folds for multi-task learning — make.folds.multi","text":"","code":"family <- \"binomial\" y <- sim.data.multiple(family=family)$y_train fold <- make.folds.multi(y=y,family=family) table(fold) #> fold #>  1  2  3  4  5  6  7  8  9 10  #> 14 11 11 11 10  9  8  8  9  9  table(y[,3],fold) #>    fold #>     1 2 3 4 5 6 7 8 9 10 #>   0 7 6 6 6 5 5 4 5 5  5 #>   1 7 5 5 5 5 4 4 3 4  4"},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.trans.html","id":null,"dir":"Reference","previous_headings":"","what":"Folds for transfer learning — make.folds.trans","title":"Folds for transfer learning — make.folds.trans","text":"Folds transfer learning","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Folds for transfer learning — make.folds.trans","text":"","code":"make.folds.trans(y, family, nfolds = 10)"},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.trans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Folds for transfer learning — make.folds.trans","text":"y list \\(q\\) numeric vectors family character \"gaussian\" \"binomial\" nfolds integer 2 n","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/make.folds.trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Folds for transfer learning — make.folds.trans","text":"","code":"family <- \"binomial\" y <- sim.data.transfer(family=family)$y_train fold <- make.folds.trans(y,family=family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean function — mean_function","title":"Mean function — mean_function","text":"Applies mean function (inverse link function).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean function — mean_function","text":"","code":"mean_function(eta, family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean function — mean_function","text":"eta numeric vector family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean function — mean_function","text":"","code":"family <- \"binomial\" eta <- seq(from=-3,to=3,length.out=100) mu <- mean_function(eta=eta,family=family) graphics::plot(x=eta,y=mu,type=\"l\",main=family) graphics::abline(v=0,lty=2) h <- ifelse(family==\"binomial\",0.5,0) graphics::abline(h=h,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/plotWeight.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualise metric that depends on two parameters — plotWeight","title":"Visualise metric that depends on two parameters — plotWeight","text":"Displays values y grey scale (white=lowest, black=highest), different combinations two variables x. lowest value indicated red cross, lowest value diagonal indicated red circle.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plotWeight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualise metric that depends on two parameters — plotWeight","text":"","code":"plotWeight(x, y)"},{"path":"https://rauschenberger.github.io/sparselink/reference/plotWeight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualise metric that depends on two parameters — plotWeight","text":"x list slots source target y numeric vector","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plotWeight.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualise metric that depends on two parameters — plotWeight","text":"","code":"values <- seq(from=0,to=1,by=0.2) x <- expand.grid(source=values,target=values) y <- stats::rexp(n=length(values)*length(values)) plotWeight(x=x,y=y)"},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":null,"dir":"Reference","previous_headings":"","what":"Make Predictions — predict.sparselink","title":"Make Predictions — predict.sparselink","text":"Predicts outcome","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make Predictions — predict.sparselink","text":"","code":"# S3 method for class 'sparselink' predict(object, newx, weight = NULL, ...)"},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make Predictions — predict.sparselink","text":"object object class `sparselink` newx features: matrix \\(n\\) rows (samples) \\(p\\) columns (variables) multi-task learning; list \\(q\\) matrices \\(n_k\\) rows (samples) \\(p\\) columns (variables) transfer learning, \\(k\\) \\(1,\\ldots,q\\) weight experimental argument: numeric vector length 2, first entry internal weight, second entry external weight, overwrites cross-validated weights ... (applicable)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make Predictions — predict.sparselink","text":"Returns predicted values predicted probabilities. output list \\(q\\) column vectors length \\(n_k\\) \\(k\\) \\(1,\\ldots,q\\).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Make Predictions — predict.sparselink","text":"Armin Rauschenberger, Petr N. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision. https://hdl.handle.net/10993/63425","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make Predictions — predict.sparselink","text":"","code":"family <- \"gaussian\" data <- sim.data.transfer(family=family) #data <- sim.data.multiple(family=family) object <- sparselink(x=data$X_train,y=data$y_train,family=family) #> alpha.init=0.95, alpha=1, trial=FALSE, type=exp #> mode: transfer learning y_hat <- predict(object=object,newx=data$X_test)"},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid function — sigmoid","title":"Sigmoid function — sigmoid","text":"Sigmoid function","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid function — sigmoid","text":"","code":"sigmoid(x)"},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid function — sigmoid","text":"x numeric vector","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid function — sigmoid","text":"","code":"x <- seq(from=-3,to=3,length.out=100) y <- sigmoid(x) graphics::plot(x=x,y=y,type=\"l\") graphics::abline(v=0,lty=2) graphics::abline(h=0.5,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Data simulation for multi-task learning — sim.data.multiple","title":"Data simulation for multi-task learning — sim.data.multiple","text":"Simulates data multi-task learning.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data simulation for multi-task learning — sim.data.multiple","text":"","code":"sim.data.multiple(   prob.common = 0.05,   prob.separate = 0.05,   q = 3,   n0 = 100,   n1 = 10000,   p = 200,   rho = 0.5,   family = \"gaussian\" )"},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data simulation for multi-task learning — sim.data.multiple","text":"prob.common probability common effect prob.separate probability separate effect q number datasets: integer n0 number training samples: integer vector length q n1 number testing samples datasets: integer p number features: integer rho correlation (decreasing structure) family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.multiple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data simulation for multi-task learning — sim.data.multiple","text":"Returns list slots y_train (\\(n_0 \\times q\\) matrix), X_train (\\(n_0 \\times p\\) matrix), y_test (\\(n_1 \\times q\\) matrix), X_test (\\(n_1 \\times p\\) matrix), beta (\\(p \\times q\\) matrix).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data simulation for multi-task learning — sim.data.multiple","text":"","code":"data <- sim.data.multiple() sapply(X=data,FUN=dim) #>      y_train X_train y_test X_test beta #> [1,]     100     100  10000  10000  200 #> [2,]       3     200      3    200    3"},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.transfer.html","id":null,"dir":"Reference","previous_headings":"","what":"Data simulation for transfer learning — sim.data.transfer","title":"Data simulation for transfer learning — sim.data.transfer","text":"Simulates data transfer learning.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.transfer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data simulation for transfer learning — sim.data.transfer","text":"","code":"sim.data.transfer(   prob.common = 0.05,   prob.separate = 0.05,   q = 3,   n0 = c(50, 100, 200),   n1 = 10000,   p = 200,   rho = 0.5,   family = \"gaussian\" )"},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.transfer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data simulation for transfer learning — sim.data.transfer","text":"prob.common probability common effect prob.separate probability separate effect q number datasets: integer n0 number training samples: integer vector length q n1 number testing samples datasets: integer p number features: integer rho correlation (decreasing structure) family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.transfer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data simulation for transfer learning — sim.data.transfer","text":"Returns list slots y_train X_train training data, y_test X_test testing data, beta effects. training data contains vectors different lengths (y_train) matrices different number rows (X_train).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim.data.transfer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data simulation for transfer learning — sim.data.transfer","text":"","code":"data <- sim.data.transfer() sapply(X=data$y_train,FUN=length) #> [1]  50 100 200 sapply(X=data$X_train,FUN=dim) #>      [,1] [,2] [,3] #> [1,]   50  100  200 #> [2,]  200  200  200 sapply(X=data$y_test,FUN=length) #> [1] 10000 10000 10000 sapply(X=data$X_test,FUN=dim) #>       [,1]  [,2]  [,3] #> [1,] 10000 10000 10000 #> [2,]   200   200   200 dim(data$beta) #> [1] 200   3"},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse regression for related problems — sparselink-package","title":"Sparse regression for related problems — sparselink-package","text":"R package `sparselink` implements sparse regression related problems (multi-task learning transfer learning).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sparse regression for related problems — sparselink-package","text":"Use function [sparselink()] model fitting. Type `library(sparselink)` `?sparselink` `help(\"sparselink\")` open help file. See vignette examples. Type `vignette(\"sparselink\")` `browseVignettes(\"sparselink\")` open vignette.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sparse regression for related problems — sparselink-package","text":"Armin Rauschenberger, Petr N. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision. https://hdl.handle.net/10993/63425","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sparse regression for related problems — sparselink-package","text":"Maintainer: Armin Rauschenberger armin.rauschenberger@uni.lu (ORCID)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse regression for related problems — sparselink-package","text":"","code":"?sparselink ?predict.sparselink ?coef.sparselink"},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse regression for related problems — sparselink","title":"Sparse regression for related problems — sparselink","text":"Estimates sparse regression models (.e., selecting variables) multi-task learning transfer learning","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse regression for related problems — sparselink","text":"","code":"sparselink(   x,   y,   family,   alpha.init = 0.95,   alpha = 1,   type = \"exp\",   nfolds = 10,   trial = FALSE )"},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse regression for related problems — sparselink","text":"x \\(n \\times p\\) matrix (multi-task learning) list \\(n_k \\times p\\) matrices (transfer learning) y \\(n \\times q\\) matrix (multi-task learning) list \\(n_k\\)-dimensional vectors (transfer learning) family character \"gaussian\" \"binomial\" alpha.init elastic net mixing parameter initial regressions, default: 0.95 (lasso-like elastic net) alpha elastic net mixing parameter final regressions, default: 1 (lasso) type character nfolds number cross-validation folds trial experimental argument (removed): exponents 1 used? Default: FALSE","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse regression for related problems — sparselink","text":"","code":"# multi-task learning n <- 100 p <- 50 q <- 3 family <- \"gaussian\" x <- matrix(data=rnorm(n=n*p),nrow=n,ncol=p) y <- matrix(data=rnorm(n*q),nrow=n,ncol=q) object <- sparselink(x=x,y=y,family=family) #> alpha.init=0.95, alpha=1, trial=FALSE, type=exp #> mode: multi-target learning  # transfer learning n <- c(100,50) p <- 50 x <- lapply(X=n,function(x) matrix(data=stats::rnorm(n*p),nrow=x,ncol=p)) y <- lapply(X=n,function(x) stats::rnorm(x)) family <- \"gaussian\" object <- sparselink(x=x,y=y,family=family) #> alpha.init=0.95, alpha=1, trial=FALSE, type=exp #> mode: transfer learning"},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":null,"dir":"Reference","previous_headings":"","what":"Train and test model — traintest","title":"Train and test model — traintest","text":"Trains tests prediction models","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train and test model — traintest","text":"","code":"traintest(   y_train,   X_train,   y_test = NULL,   X_test = NULL,   family,   alpha,   method = c(\"glm.separate\", \"glm.glmtrans\", \"sparselink\", \"glm.common\"),   alpha.init,   type,   trial = FALSE )"},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train and test model — traintest","text":"y_train target training samples: vector length n X_train features training samples: \\(n \\times p\\) matrix y_test target testing samples: vector length \\(m\\) X_test features testing samples \\(m \\times p\\) matrix family character \"gaussian\" \"binomial\" alpha elastic net mixing parameter method character vector alpha.init elastic net mixing parameter initial regressions type character trial see sparselink","code":""},{"path":"https://rauschenberger.github.io/sparselink/news/index.html","id":"sparselink-001-2024-11-29","dir":"Changelog","previous_headings":"","what":"sparselink 0.0.1 (2024-11-29)","title":"sparselink 0.0.1 (2024-11-29)","text":"development","code":""}]
