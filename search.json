[{"path":"https://rauschenberger.github.io/sparselink/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing guidelines","title":"Contributing guidelines","text":"encounter bug R package sparselink, please report GitHub Issues. Ideally, provide minimal reproducible example (.e., lines code can copy--paste R console obtain error).","code":""},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"working-environment","dir":"Articles","previous_headings":"","what":"Working environment","title":"Analysis code","text":"vignette includes code chunks long computation time (e.g., analysing simulated experimental data) code chunks short computation time (e.g., generating figures tables). logical options sim.app fig.tab determine whether chunks () running simulation application (ii) generating figures tables evaluated, respectively. Running vignette sim.app=FALSE fig.tab=TRUE means figures tables generated previously obtained results. Running vignette sim.app=TRUE fig.tab=TRUEand means results reproduced (including data download data processing). also possible execute individual chunks (e.g., reproducing specific figure table), important provide required inputs (e.g., “Requires: file X folder Y, execution chunk Z”). chunk verifies working environment. working directory, specified object path, must contain R functions “package/R/functions.R” well folders “results” “manuscript”. Alternatively, R functions can loaded R package sparselink. chunk also installs missing R packages CRAN Bioconductor.","code":"knitr::opts_chunk$set(echo=TRUE,eval=FALSE) sim.app <- FALSE # reproduce simulation and application? fig.tab <- FALSE # reproduce figures and tables? path <- \"C:/Users/arauschenberger/Desktop/sparselink\" # LIH (Windows) #path <- \"/Users/armin.rauschenberger/Desktop/LIH/sparselink\" # LCSB (Mac)  dir <- c(\"results\",\"manuscript\",\"package/R/functions.R\") for(i in seq_along(dir)){   if(!dir.exists(file.path(path,dir[i]))&!file.exists(file.path(path,dir[i]))){     stop(paste0(\"Require folder/file'\",dir[i],\"'.\"))   }  } source(file.path(path,\"package/R/functions.R\")) # Or load 'sparselink' package.  inst <- rownames(utils::installed.packages()) pkgs <- c(\"knitr\",\"rmarkdown\",\"glmnet\",\"BiocManager\",\"mvtnorm\",\"glmtrans\",\"spls\",\"xrnet\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     utils::install.packages(pkgs[i])   } } pkgs <- c(\"recount3\",\"edgeR\") for(i in seq_along(pkgs)){   if(!pkgs[i]%in%inst){     BiocManager::install(pkgs[i])   } }  blue <- \"blue\"; red <- \"red\"  if(exists(\"sim.app\")&exists(\"fig.tab\")){   if(!sim.app&fig.tab){     files <- c(\"simulation_multiple.RData\",\"simulation_transfer.RData\",\"recount3_data.RData\",\"explore_data.RData\",\"application.RData\")     for(i in seq_along(files)){       if(!file.exists(file.path(path,\"results\",files[i]))){         stop(\"File\",files[i],\"is missing.\")       }     }   } }"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Analysis code","text":"chunk generates figure methods section. Requires: execution chunk setup Execution time: \\(1\\) second Ensures: file fig_flow.eps folder manuscript","code":"#<<setup>>  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_flow.eps\"),width=6,height=2.5,horizontal=FALSE,onefile=FALSE,paper=\"special\") graphics::par(mfrow=c(1,1),mar=c(0,0,0,0)) graphics::plot.new() graphics::plot.window(xlim=c(-0.2,1.0),ylim=c(0.0,1.0)) cex <- 0.8  pos <- data.frame(left=0.2,right=0.8,top=0.8,centre=0.45,bottom=0.1) mar <- data.frame(vertical=0.08,horizontal=0.08,dist=0.04)  graphics::text(labels=paste(\"problem\",1:2),x=c(pos$left,pos$right),y=pos$top+2*mar$vertical,font=2,col=c(blue,red),cex=cex) graphics::text(labels=expression(hat(beta)[\"j,1\"]^{init}),x=pos$left,y=pos$top,col=blue) graphics::text(labels=expression(hat(beta)[\"j,2\"]^{init}),x=pos$right,y=pos$top,col=red)  graphics::arrows(x0=rep(c(pos$left,pos$right),each=2),x1=rep(c(pos$left,pos$right),times=2)+c(-mar$horizontal,-mar$horizontal,mar$horizontal,mar$horizontal),y0=pos$top-mar$vertical,y1=pos$centre+mar$vertical,length=0.1,col=rep(c(blue,red),each=2),lwd=2)  graphics::text(labels=expression(w[\"j,1\"]^{int}),x=pos$left-mar$horizontal-mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"p+j,1\"]^{int}),x=pos$left-mar$horizontal+mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"j,1\"]^{ext}),x=pos$left+mar$horizontal-mar$dist,y=pos$centre,col=red) graphics::text(labels=expression(w[\"p+j,1\"]^{ext}),x=pos$left+mar$horizontal+mar$dist,y=pos$centre,col=red)  graphics::text(labels=expression(w[\"j,2\"]^{ext}),x=pos$right-mar$horizontal-mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"p+j,2\"]^{ext}),x=pos$right-mar$horizontal+mar$dist,y=pos$centre,col=blue) graphics::text(labels=expression(w[\"j,2\"]^{int}),x=pos$right+mar$horizontal-mar$dist,y=pos$centre,col=red) graphics::text(labels=expression(w[\"p+j,2\"]^{int}),x=pos$right+mar$horizontal+mar$dist,y=pos$centre,col=red)  graphics::arrows(x0=c(pos$left,pos$right),y0=pos$centre-mar$vertical,y1=pos$bottom+mar$vertical,col=c(blue,red),length=0.1,lwd=2) graphics::text(labels=expression(hat(beta)[\"j,1\"]^{final}==hat(gamma)[\"j,1\"]-hat(gamma)[\"p+j,1\"]),x=pos$left,y=pos$bottom,col=blue) graphics::text(labels=expression(hat(beta)[\"j,2\"]^{final}==hat(gamma)[\"j,2\"]-hat(gamma)[\"p+j,2\"]),x=pos$right,y=pos$bottom,col=red)  graphics::text(x=-0.1,y=c(pos$top,pos$bottom),labels=paste(\"stage\",1:2),font=2,cex=cex) grDevices::dev.off()"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Analysis code","text":"chunk performs simulation. Requires: execution chunk setup Execution time: 0.5 hours Ensures: files simulation_transfer.RData (transfer learning), simulation_multiple.RData (multi-task learning) info_sim.txt (session information) folder results following chunk generate figures simulation study. Requires: execution chunk setup, files simulation_transfer.RData simulation_multiple.RData folder results (generated chunk simulation) execution time: \\(1\\) second Ensures: files fig_sim_multiple.eps fig_sim_transfer.eps folder manuscript","code":"#<<setup>>  repetitions <- 10  for(mode in c(\"transfer\",\"multiple\")){      grid <- expand.grid(prob.separate=c(0.0,0.025,0.05),prob.common=c(0.0,0.025,0.05),family=\"gaussian\")   grid <- grid[rep(seq_len(nrow(grid)),each=repetitions),] #   grid$seed <- seq_len(nrow(grid))   grid$family <- as.character(grid$family)   deviance <- auc <- time <- mse.coef <- mse.zero <- mse.nzero <- sel.num <- sel.coef <- sel.count <- hyperpar <- list()   for(i in seq(from=1,to=nrow(grid))){     set.seed(seed=grid$seed[i])     cat(\"i=\",i,\"\\n\")     if(mode==\"transfer\"){       data <- sim_data_trans(prob.common=grid$prob.common[i],prob.separate=grid$prob.separate[i],family=grid$family[i])       method <- c(\"wrap_separate\",\"wrap_glmtrans\",\"sparselink\",\"wrap_xrnet\")     } else if(mode==\"multiple\"){       #--- multi-task learning ---       data <- sim_data_multi(prob.common=grid$prob.common[i],prob.separate=grid$prob.separate[i],family=grid$family[i])       method <- c(\"wrap_separate\",\"wrap_mgaussian\",\"sparselink\",\"wrap_spls\")     }          result <- traintest(y_train=data$y_train,X_train=data$X_train,y_test=data$y_test,X_test=data$X_test,family=grid$family[i],method=method)     hyperpar[[i]] <- result$hyperpar     time[[i]] <- result$time     auc[[i]] <- result$auc     deviance[[i]] <- result$deviance     sel.num[[i]] <- t(sapply(result$coef,function(x) colSums(x!=0)))     sel.count[[i]] <- t(sapply(result$coef,function(x) rowMeans(count_matrix(truth=sign(data$beta),estim=sign(x))))) # Add na.rm=TRUE?          sel.coef[[i]] <- t(sapply(result$coef,function(x) colMeans(sign(x)!=sign(data$beta))))     # CONTINUE HERE: consider sparsity, true positives, false negatives, signs          mse.coef[[i]] <- t(sapply(result$coef,function(x) colMeans((data$beta-x)^2)))     mse.zero[[i]] <- t(sapply(result$coef,function(x) colMeans(((data$beta==0)*(data$beta-x))^2)))     mse.nzero[[i]] <- t(sapply(result$coef,function(x) colMeans(((data$beta!=0)*(data$beta-x))^2)))   }   save(grid,deviance,auc,sel.num,sel.count,sel.coef,mse.coef,mse.zero,mse.nzero,time,file=file.path(path,\"results\",paste0(\"simulation_\",mode,\".RData\"))) }  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),      sessioninfo::session_info()),con=paste0(path,\"/results/info_sim.txt\")) #<<setup>>  caption <- paste(c(\"\\\\textbf{Multi-task learning.}\",\"\\\\textbf{Transfer learning.}\"),\"Comparison of different measures (rows) between an available method (red) and the proposed method (blue) in different simulation settings (columns), based on the average of three problems\",c(\"(tasks)\",\"(datasets)\"),\"for each repetition out of ten. Measures: performance metric (mean squared error on hold-out data, as a fraction of the one from standard lasso regression; a point below the dashed line means that\",c(\"multi-task\",\"transfer\"),\"learning improves predictions), sparsity (number of non-zero coefficients), precision (number of coefficients with correct signs divided by number of non-zero coefficients). The arrows point in the direction of improvement. Settings: percentage of features with a common effect for all problems ($\\\\pi_\\\\theta$), percentage of features with a specific effect for each problem ($\\\\pi_\\\\delta$).\",c(\"\\\\label{fig_sim_multiple}\",\"\\\\label{fig_sim_transfer}\"))  figure_change <- function(model0,model1=\"sparselink\",model2){      mode <- paste0(100*grid$prob.common,\"%\\n\",100*grid$prob.separate,\"%\")      graphics::par(mfrow=c(3,1),mar=c(3,3,1,1))      label <- function(){     cex <- 0.5     at <- 0.3     graphics::mtext(text=expression(pi[theta]==phantom(.)),side=1,line=0.2,at=at,cex=cex)     graphics::mtext(text=expression(pi[delta]==phantom(.)),side=1,line=1.2,at=at,cex=cex)   }      #--- predictive performance ---   means <- t(sapply(X=deviance,FUN=rowMeans))   means <- means/means[,\"wrap_separate\"]   plot_change(x=mode,y0=means[,model0],y1=means[,model1],y2=means[,model2],main=\"metric\",increase=FALSE)   graphics::abline(h=1,lty=2,col=\"grey\")   label()      #--- sparsity ---   nzero <- sapply(X=sel.num,FUN=rowMeans)   plot_change(x=mode,y0=nzero[model0,],y1=nzero[model1,],y2=nzero[model2,],main=\"sparsity\",increase=FALSE)      graphics::abline(h=0,lty=2,col=\"grey\")   label()      #--- precision ---   precision <- sapply(X=sel.count,FUN=function(x) x[,\"precision\"])   precision[is.na(precision)] <- 0   plot_change(x=mode,y0=precision[model0,],y1=precision[model1,],y2=precision[model2,],main=\"precision\",increase=TRUE)      graphics::abline(h=0,lty=2,col=\"grey\")   label()    }  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_sim_multiple.eps\"),width=6.5,height=6,horizontal=FALSE,onefile=FALSE,paper=\"special\") load(file.path(path,paste0(\"results/simulation_multiple.RData\")),verbose=TRUE) #model.ref <- \"wrap_mgaussian\" #model.own <- \"sparselink\" figure_change(model0=\"wrap_mgaussian\",model1=\"sparselink\",model2=\"wrap_spls\") rowMeans(sapply(deviance,function(x) rank(rowMeans(x)))) rowMeans(sapply(deviance,function(x) colMeans(t(x)/x[\"wrap_separate\",]))) runtime <- rowSums(sapply(time,function(x) x)) round(runtime/runtime[\"wrap_separate\"],digits=2) grDevices::dev.off()  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_sim_transfer.eps\"),width=6.5,height=6,horizontal=FALSE,onefile=FALSE,paper=\"special\") load(file.path(path,paste0(\"results/simulation_transfer.RData\"))) #model.ref <- \"wrap_glmtrans\" #model.own <- \"sparselink\" figure_change(model0=\"wrap_glmtrans\",model1=\"sparselink\",model2=\"wrap_xrnet\") rowMeans(sapply(deviance,function(x) rank(rowMeans(x)))) rowMeans(sapply(deviance,function(x) colMeans(t(x)/x[\"wrap_separate\",]))) runtime <- rowSums(sapply(time,function(x) x)) round(runtime/runtime[\"wrap_separate\"],digits=2) grDevices::dev.off()"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"sample-size-and-sparsity-revision","dir":"Articles","previous_headings":"Simulation","what":"Sample size and sparsity (revision)","title":"Analysis code","text":"","code":"# Effect of sample size in source or target dataset (TL), effect of sample size (MTL). #<<setup>>  repetitions <- 50 grid <- metric <- list()  for(mode in c(\"MTL-size\",\"TL-source\",\"TL-target\")){ #,\"TL-prop\",\"MTL-prop\"   metric[[mode]] <- list()   cand <- c(20,40,60,80,100)   if(mode==\"MTL-size\"){     grid[[mode]] <- expand.grid(prob.common=0.05,prob.separate=0.025,family=\"gaussian\",n0=cand)   } else if(mode==\"TL-source\"){     grid[[mode]] <- expand.grid(prob.common=0.05,prob.separate=0.025,family=\"gaussian\",n_source=cand,n_target=50)   } else if(mode==\"TL-target\"){     grid[[mode]] <- expand.grid(prob.common=0.05,prob.separate=0.025,family=\"gaussian\",n_source=50,n_target=cand)   } else if(mode %in% c(\"TL-prop\",\"MTL-prop\")){     cand <- c(0.025,0.05,0.10,0.15,0.20)     grid[[mode]] <- expand.grid(prob.common=cand,prob.separate=NA,family=\"gaussian\",n_source=50,n_target=50,n0=50)   } else {     stop(\"Wrong mode.\")   }   grid[[mode]] <- grid[[mode]][rep(seq_len(nrow(grid[[mode]])),each=repetitions),]   #grid[[mode]]$seed <- seq_len(nrow(grid[[mode]]))   grid[[mode]]$seed <- rep(x=seq_len(repetitions),times=length(cand))   grid[[mode]]$family <- as.character(grid[[mode]]$family)   cond <- is.na(grid[[mode]]$prob.separate)   grid[[mode]]$prob.separate[cond] <- 0.5*grid[[mode]]$prob.common[cond]      for(i in seq(from=1,to=nrow(grid[[mode]]))){       set.seed(seed=grid$seed[i])       cat(\"i=\",i,\"\\n\")       if(mode %in% c(\"TL-source\",\"TL-target\",\"TL-prop\")){         n0 <- rep(c(grid[[mode]]$n_source[i],grid[[mode]]$n_target[i]),times=c(2,1))         data <- sim_data_trans(prob.common=grid[[mode]]$prob.common[i],prob.separate=grid[[mode]]$prob.separate[i],family=grid[[mode]]$family[i],n0=n0)         method <- c(\"wrap_separate\",\"wrap_glmtrans\",\"sparselink\",\"wrap_xrnet\")       } else if(mode %in% c(\"MTL-size\",\"MTL-prop\")){         data <- sim_data_multi(prob.common=grid[[mode]]$prob.common[i],prob.separate=grid[[mode]]$prob.separate[i],family=grid[[mode]]$family[i],n0=grid[[mode]]$n0[i])         method <- c(\"wrap_separate\",\"wrap_mgaussian\",\"sparselink\",\"wrap_spls\")       } else {         stop(\"Wrong mode.\")       }       result <- traintest(y_train=data$y_train,X_train=data$X_train,y_test=data$y_test,X_test=data$X_test,family=grid[[mode]]$family[i],method=method)       metric[[mode]][[i]] <- result$deviance     } }  save(grid,metric,file=file.path(path,\"results\",\"simulation_devel.RData\"))  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),      sessioninfo::session_info()),con=paste0(path,\"/results/info_sim_extra.txt\")) #<<setup>> load(file.path(path,\"results\",\"simulation_devel.RData\"))  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_sim_extra.eps\"),width=6.5,height=3,horizontal=FALSE,onefile=FALSE,paper=\"special\") cex <- 0.8 graphics::par(mfrow=c(1,3),mar=c(4.5,4.5,1.5,1),oma=c(0,0,0,0)) #graphics::layout(mat=matrix(data=c(1,1,2,2,3,3,0,4,4,0,5,5),ncol=2)) for(mode in c(\"MTL-size\",\"TL-source\",\"TL-target\")){ #for(mode in c(\"MTL-prop\",\"TL-prop\")){   if(mode %in% c(\"MTL-size\",\"MTL-prop\",\"TL-prop\")){     mse <- sapply(metric[[mode]],function(x) rowMeans(x))   } else if(mode %in% c(\"TL-source\",\"TL-target\")){     mse <- sapply(metric[[mode]],function(x) x[,3])   }   if(mode %in% c(\"TL-source\",\"TL-target\",\"TL-prop\")){     col <- c(\"wrap_separate\"=\"black\",\"wrap_glmtrans\"=\"red\",\"wrap_xrnet\"=\"orange\",\"sparselink\"=\"blue\")     lty <- c(\"wrap_separate\"=3,\"wrap_glmtrans\"=2,\"wrap_xrnet\"=2,\"sparselink\"=1)   } else if(mode %in% c(\"MTL-size\",\"MTL-prop\")) {     col <- c(\"wrap_separate\"=\"black\",\"wrap_mgaussian\"=\"red\",\"wrap_spls\"=\"orange\",\"sparselink\"=\"blue\")     lty <- c(\"wrap_separate\"=3,\"wrap_mgaussian\"=2,\"wrap_spls\"=2,\"sparselink\"=1)   }   if(mode==\"TL-source\"){     params <- grid[[mode]]$n_source   } else if(mode==\"TL-target\"){     params <- grid[[mode]]$n_target   } else if(mode==\"MTL-size\"){     params <- grid[[mode]]$n0   } else if(mode %in% c(\"TL-prop\",\"MTL-prop\")){     params <- grid[[mode]]$prob.common   }   unique <- unique(params)   graphics::plot.new()   graphics::plot.window(xlim=range(params),ylim=range(log(mse)))   graphics::box()   if(mode==\"MTL-size\"){     main <- \"MTL - varying sample size\"     xlab <- bquote(\"sample size (\"~n[1]~\"=\"~n[2]~\"=\"~n[3]~\")\")     legend <- \"\"   } else if(mode==\"TL-source\"){     main <- \"TL - varying source sample size\"     xlab <- bquote(\"source sample size (\"~n[1]~\"=\"~n[2]~\")\")     legend <- bquote(\"target sample size:\"~n[3]==.(unique(grid[[mode]]$n_target)))   } else if(mode==\"TL-target\"){     main <- \"TL - varying target sample size\"     xlab <- bquote(\"target sample size (\"~n[3]~\")\")     legend <- bquote(\"source sample size:\"~n[1]~\"=\"~n[2]==.(unique(grid[[mode]]$n_source)))   } else if(mode==\"MTL-prop\"){     xlab <- \"blabla\"     main <- \"MTL - effect proportion\"     legend <- \"\"   } else if(mode==\"TL-prop\"){     xlab <- \"blabla\"     main <- \"TL - effect proportion\"     legend <- \"\"   }   graphics::title(main=main,cex.main=cex)   graphics::title(ylab=\"log MSE\",line=2.5,xlab=xlab,cex.lab=cex)   graphics::legend(x=\"topleft\",legend=legend,bty=\"n\",cex=cex)   if(mode %in% c(\"TL-prop\",\"MTL-prop\")){     graphics::axis(side=1,at=unique,labels=paste0(100*unique,\"%\"),cex.axis=cex)   } else {     graphics::axis(side=1,at=unique,cex.axis=cex)   }   graphics::axis(side=2,cex.axis=cex)      for(i in names(col)){     val <- tapply(X=mse[i,],INDEX=params,FUN=function(x) mean(x))     graphics::lines(x=unique,y=log(val),col=col[i],type=\"o\",pch=16,lty=lty[i])   } } grDevices::dev.off()"},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"data-preparation","dir":"Articles","previous_headings":"Application","what":"Data preparation","title":"Analysis code","text":"chunk defines references project identifiers application. Requires: nothing Execution time: \\(1\\) second Ensures: list project working environment chunk downloads data application. Requires: execution chunks setup define_projects Execution time: depends internet speed cached files Ensures: files recount3_data.RData (data sets) info_data.txt (system information) folder results chunk preprocesses data. Requires: execution chunks setup define_projects, file recount3_data.RData (generated chunk download_data) Execution time: \\(5\\) seconds Ensures: lists y (targets) x (features) working environment","code":"project <- list() project$IBD <- c(\"Tew (2016)\"=\"SRP063496\",                  \"Haberman (2019)\"=\"SRP129004\",                  \"Verstockt (2019)\"=\"ERP113396\",                  \"Verstockt (2020)\"=\"ERP114636\",                  \"Boyd (2018)\"=\"SRP100787\") project$RA <- c(\"Baker (2019)\"=\"SRP169062\",                 \"Moncrieffe (2017)\"=\"SRP074736\",                 \"Goldberg (2018)\"=\"SRP155483\") extra <- c(\"Lewis (2019)\"=\"ERP104864\") # https://doi.org/10.1016/j.celrep.2019.07.091 #<<setup>> #<<define_projects>>  data <- list() for(i in c(unlist(project),extra)){   data[[i]] <- recount3::create_rse_manual(     project=i,     project_home=\"data_sources/sra\",     organism=\"human\",     annotation = \"gencode_v26\",     type=\"gene\") } save(data,file=file.path(path,\"results/recount3_data.RData\"))  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),       sessioninfo::session_info()),con=paste0(path,\"/results/info_data.txt\")) #<<setup>> #<<define_projects>>  load(file.path(path,\"results/recount3_data.RData\"))  #- - - - - - - - - - - - - - - #- - - extract features  - - -  #- - - - - - - - - - - - - - -  # extract features x <- list() for(i in c(unlist(project),extra)){   counts <- t(SummarizedExperiment::assays(data[[i]])$raw_counts)   colnames(counts) <- SummarizedExperiment::rowRanges(data[[i]])$gene_name   x[[i]] <- counts }  # select most expressed protein-coding genes (for all TL projects together) select <- list() total <- numeric() for(i in unlist(project)){   #total <- rbind(total,Matrix::colSums(x[[i]])) # original: mean filtering   total <- rbind(total,apply(X=x[[i]],MARGIN=2,FUN=stats::var)) # trial: variance filtering } type <- SummarizedExperiment::rowData(data[[i]])$gene_type cond <- type==\"protein_coding\" total[,!cond] <- 0 rank <- apply(X=total,MARGIN=1,FUN=rank) mean_rank <- rowMeans(rank) #temp <- cond & apply(total,2,function(x) all(x>0)) & (mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[2000]) # original: top 2000 temp <- cond & mean_rank >= sort(mean_rank[cond],decreasing=TRUE)[5000] # trial: top 5000  for(i in unlist(project)){   select[[i]] <- temp }  # select most expressed protein-coding genes (for MTL project) #mean <- apply(X=x[[extra]],MARGIN=2,FUN=mean) # original var <- apply(X=x[[extra]],MARGIN=2,FUN=var) # trial #warning(\"change number in next line\") #temp <- cond & mean >= sort(mean[cond],decreasing=TRUE)[5000] # trial: top 5000 temp <- cond & var >= sort(var[cond],decreasing=TRUE)[5000] # trial: top 5000 select[[extra]] <- temp  # pre-processing for(i in c(unlist(project),extra)){   lib.size <- Matrix::rowSums(x[[i]])   x[[i]] <- x[[i]][,select[[i]],drop=FALSE]   norm.factors <- edgeR::calcNormFactors(object=t(x[[i]]),lib.size=lib.size)   gamma <- norm.factors*lib.size/mean(lib.size)   gamma <- matrix(data=gamma,nrow=nrow(x[[i]]),ncol=ncol(x[[i]]))   x[[i]] <- x[[i]]/gamma   x[[i]] <- 2*sqrt(x[[i]] + 3/8) # Anscombe transform   x[[i]] <- scale(x[[i]]) # scale because of different datasets!? }  #- - - - - - - - - - - - - - #- - - extract targets - - - #- - - - - - - - - - - - - -  # extract information on samples frame <- list() for(i in c(unlist(project),extra)){   list <- strsplit(data[[i]]$sra.sample_attributes,split=\"\\\\|\")   data[[i]]$sra.experiment_attributes   # What about sra.experiment_attributes?   n <- length(list)   cols <- unique(sapply(strsplit(unlist(list),split=\";;\"),function(x) x[1]))   ncol <- length(cols)   frame[[i]] <- matrix(data=NA,nrow=n,ncol=ncol,dimnames=list(rownames(x[[i]]),cols))   for(j in seq_len(n)){     for(k in seq_len(ncol)){       vector <- list[[j]]       which <- which(substring(text=vector,first=1,last=nchar(cols[k]))==cols[k])       string <- vector[which]       if(length(string)==0){next}       frame[[i]][j,k] <- strsplit(string,split=\";;\")[[1]][2]     }   }   frame[[i]] <- as.data.frame(frame[[i]]) }  # extract binary outcome y <- z <- list() for(i in unlist(project)){   # CONTINUE HERE!!!   if(i==\"ERP113396\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical history`,FUN=function(x) switch(EXPR=x,\"responder\"=1,\"non-responder\"=0,stop(\"invalid\")))   } else if(i==\"ERP114636\"){     y[[i]] <- sapply(X=frame[[i]]$`clinical information`,FUN=function(x) switch(EXPR=x,\"response to vedolizumab therapy\"=1-1,\"no response to vedolizumab therapy\"=0+1,stop(\"invalid\")))     warning(\"Inverting response and non-response!\")   } else if(i==\"SRP100787\"){     y[[i]] <- sapply(X=frame[[i]]$condition,FUN=function(x) switch(EXPR=x,\"CD inactive\"=1,\"UC inactive\"=1,\"CD active\"=0,\"UC active\"=0,control=NA,\"NA\"=NA,stop(\"invalid\")))   } else if(i==\"SRP129004\"){     y[[i]] <- sapply(X=frame[[i]]$`week 4 remission`,FUN=function(x) switch(EXP=x,\"Yes\"=1,\"No\"=0,\"NA\"=NA,stop(\"invalid\")))     suppressWarnings(z[[i]] <- data.frame(pucai=as.numeric(frame[[i]]$pucai),mayo=as.numeric(frame[[i]]$`total mayo score`),histology=as.numeric(frame[[i]]$`histology severity score`)))   } else if(i==\"SRP063496\"){     y[[i]] <- sapply(X=frame[[i]]$`remission at week 10`,FUN=function(x) switch(x, \"Remitter\"=1,\"Non-remitter\"=0,\"N/A\"=NA,stop(\"invalid\")))   } else if(i==\"SRP169062\"){     y[[i]] <- sapply(X=frame[[i]]$`flare event`,FUN=function(x) switch(x,\"no flare\"=1,\"flare\"=0,stop(\"invalid\")))   } else if(i==\"SRP155483\"){     y[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=1,\"Low\"=0,\"Moderate\"=0,\"High\"=0,\"--\"=NA,stop(\"invalid\")))     z[[i]] <- sapply(X=frame[[i]]$`disease activity`,FUN=function(x) switch(x,\"remission\"=0,\"Low\"=1,\"Moderate\"=2,\"High\"=3,\"--\"=NA,stop(\"invalid\")))   } else if(i==\"SRP074736\"){     y[[i]] <- sapply(X=frame[[i]]$`mtx response status`,FUN=function(x) switch(x,\"responder\"=1,\"non-responder\"=0,\"control\"=NA,stop(\"invalid\")))   } }  # overlap for(j in unlist(project)){   is.na <- is.na(y[[j]])   if(length(is.na)!=nrow(x[[j]])){stop()}   y[[j]] <- y[[j]][!is.na]   if(!is.null(z[[j]])){     if(is.vector(z[[j]])){       z[[j]] <- z[[j]][!is.na]     } else {       z[[j]] <- z[[j]][!is.na,]     }   }   x[[j]] <- x[[j]][!is.na,] }"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"data-exploration","dir":"Articles","previous_headings":"Application","what":"Data exploration","title":"Analysis code","text":"chunk performs exploratory data analysis. Requires: execution chunks setup, define_projects preprocess_data Execution time: \\(0.5\\) minutes Ensures: files explore_data.RData (results) info_explore.txt (session information) folder results chunk generates tables exploratory data analysis. Requires: execution chunk setup, file explore_data.RData folder results (generated chunk explore_apply) execution time: \\(1\\) second Ensures: files tab_cor.tex tab_auc.tex folder manuscript","code":"#<<setup>> #<<define_projects>> #<<preprocess_data>>  set.seed(1) alpha.holdout <- 0 alpha.crossval <- 1 family <- \"binomial\" nfolds <- 10 codes <- unlist(project) coef <- matrix(data=NA,nrow=ncol(x[[1]]),ncol=length(codes),dimnames=list(NULL,codes)) auc <- auc.pvalue <- matrix(data=NA,nrow=length(codes),ncol=length(codes),dimnames=list(codes,codes)) foldid <- make_folds_trans(y=y,family=\"binomial\",nfolds=nfolds)  ridge <- lasso <- list() for(i in seq_along(codes)){   ridge[[i]] <- glmnet::cv.glmnet(x=x[[codes[i]]],y=y[[codes[i]]],family=family,alpha=alpha.holdout,foldid=foldid[[i]])   coef[,i] <- stats::coef(ridge[[i]],s=\"lambda.min\")[-1]   for(j in seq_along(codes)){     if(i==j){       y_hat <- rep(x=NA,times=length(y[[i]]))       for(k in seq_len(nfolds)){         holdout <- foldid[[i]]==k         temp <- glmnet::cv.glmnet(x=x[[codes[i]]][!holdout,],y=y[[codes[i]]][!holdout],family=family,alpha=alpha.crossval)         y_hat[holdout] <- predict(object=temp,newx=x[[codes[i]]][holdout,],s=\"lambda.min\",type=\"response\")       }     } else {       y_hat <- as.numeric(predict(object=ridge[[i]],newx=x[[j]],s=\"lambda.min\",type=\"response\"))     }     auc[i,j] <- pROC::auc(response=y[[codes[j]]],predictor=y_hat,direction=\"<\",levels=c(0,1))     auc.pvalue[i,j] <- stats::wilcox.test(rank(y_hat)~y[[codes[[j]]]],alternative=\"less\",exact=FALSE)$p.value   } }  save(coef,auc,auc.pvalue,codes,file=file.path(path,\"results\",\"explore_data.RData\"))  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),       sessioninfo::session_info()),con=paste0(path,\"/results/info_explore.txt\")) #<<setup>> #if(any(unlist(project)!=names(refs))){stop(\"not compatible\")}  load(file.path(path,\"results/explore_data.RData\")) names <- gsub(pattern=\"IBD.|RA.\",replacement=\"\",x=names(unlist(project))) codes <- colnames(coef) cor.pvalue <- matrix(data=NA,nrow=length(codes),ncol=length(codes),dimnames=list(codes,codes)) for(i in seq_along(codes)){   for(j in seq_along(codes)){     cor.pvalue[i,j] <- stats::cor.test(x=coef[,i],y=coef[,j],method=\"spearman\",exact=FALSE)$p.value   } } diag(cor.pvalue) <- NA  insert.space <- function(table,cut){   index.left <- index.top <- seq_len(cut)   index.right <- index.bottom <- seq(from=cut+1,to=ncol(table))   top <- cbind(table[index.top,index.left],\"\",table[index.top,index.right])   bottom <- cbind(table[index.bottom,index.left],\"\",table[index.bottom,index.right])   out <- rbind(top,\"\",bottom)   colnames(out)[colnames(out)==\"\"] <- \" \"   return(out) }  table <- stats::cor(coef,method=\"spearman\") rownames(table) <- colnames(table) <- names black <- (!is.na(cor.pvalue)) & (cor.pvalue<=0.05) star <- (!is.na(cor.pvalue)) & (cor.pvalue<=0.05/choose(n=length(codes),k=2)) nonnegative <- table>=0 table <- format(round(table,digits=2),digits=2,trim=TRUE) table[nonnegative] <- paste0(\"\\\\phantom{-}\",table[nonnegative]) table[!black] <- paste0(\"\\\\textcolor{gray}{\",table[!black],\"}\") table[star] <- paste0(table[star],\"$^\\\\star$\") table[!star] <- paste0(table[!star],\"\\\\phantom{$^\\\\star$}\") #table[nonnegative] <- paste0(\"-\",table[nonnegative]) diag(table) <- \"-\" table <- insert.space(table=table,cut=5) xtable <- xtable::xtable(x=table,align=\"rccccccccc\",caption=\"Spearman correlation coefficients between the ridge regression coefficients from different datasets. Pairwise combinations of datasets with significantly correlated regression coefficients are highlighted, with black colour for nominal significance ($p$-value $\\\\leq 0.05$) and stars for adjusted significance ($p$-value $\\\\leq 0.05/28$). We expect a correlation coefficient close to $0$ for unrelated problems and close to $1$ for identical problems.\",label=\"tab_cor\") xtable::print.xtable(x=xtable,sanitize.text.function=identity,rotate.colnames=TRUE,caption.placement=\"top\",hline.after=c(0,nrow(table)),comment=FALSE,file=file.path(path,\"manuscript\",\"tab_cor.tex\"),floating.environment=\"table*\") #add.to.row=list(pos=list(5),command=\"\\\\hdashline \\n\")  table <- auc rownames(table) <- colnames(table) <- names table <- format(round(table,digits=2),digits=2) black <- auc.pvalue<=0.05 star <- auc.pvalue<=0.05/(length(codes)*length(codes)) diag(table) <- paste0(\"(\",diag(table),\")\") table[!black] <- paste0(\"\\\\textcolor{gray}{\",table[!black],\"}\") table[star] <- paste0(table[star],\"$^\\\\star$\") table[!star] <- paste0(table[!star],\"\\\\phantom{$^\\\\star$}\") table <- insert.space(table=table,cut=5) xtable <- xtable::xtable(x=table,align=\"rccccccccc\",caption=\"Out-of-sample area under the receiver operating characteristic curve (\\\\textsc{roc-auc}) from logistic ridge regression trained on the dataset in the row and tested on the dataset in the column (off-diagonal entries), or cross-validated \\\\textsc{roc-auc} from logistic lasso regression trained and tested on the same dataset by $10$-fold external cross-validation (diagonal entries, between brackets). The \\\\textsc{roc-auc} of a random classifier is $0.5$, while that of a perfect classifier is $1.0$. Entries on and off the diagonal are not comparable. Predictions that are significantly better than random predictions (according to the one-sided Mann-Whitney $U$ test for testing whether the ranks of the predicted probabilities are significantly higher for the cases than for the controls) are highlighted, with black colour for nominal significance ($p$-value $\\\\leq 0.05$) and stars for adjusted significance ($p$-value $\\\\leq 0.05/64$).\",label=\"tab_auc\") xtable::print.xtable(x=xtable,sanitize.text.function=identity,rotate.colnames=TRUE,caption.placement=\"top\",hline.after=c(0,nrow(table)),comment=FALSE,file=file.path(path,\"manuscript\",\"tab_auc.tex\"),floating.environment=\"table*\")"},{"path":"https://rauschenberger.github.io/sparselink/articles/analysis.html","id":"transfer-learning","dir":"Articles","previous_headings":"Application","what":"Transfer learning","title":"Analysis code","text":"chunk performs transfer learning analysis. Requires: execution chunks setup define_projects, file recount3_data.RData folder results (generated chunk download_data), execution chunk preprocess_data Execution time: 1.5 hours Ensures: application.RData (results) info_app.txt (session information) folder results chunk generates figure predictive performance. Requires: execution chunk setup, file application.RData folder results (generated chunk transfer_apply) Execution time: \\(1\\) second Ensures: file fig_app.eps folder manuscript chunk generates figure feature selection. Requires: execution chunk setup, file application.RData folder results (generated chunk transfer_apply) Execution time: \\(1\\) second Ensures: file fig_coef.eps folder manuscript chunk saves session information generating figures tables.","code":"#<<setup>> #<<define_projects>> #<<preprocess_data>>  result <- list() for(i in names(project)){   cat(\"project:\",i,\"\\n\")   result[[i]] <- list()   for(j in seq_len(5)){ # 5 repetitions of 10-fold CV     set.seed(j)     codes <- project[[i]]     result[[i]][[j]] <- cv_transfer(y=y[codes],X=x[codes],family=\"binomial\",method=c(\"wrap_separate\",\"wrap_glmtrans\",\"sparselink\",\"wrap_xrnet\"),alpha.init=ifelse(i==\"RA\",0,0.95)) # lasso-like elastic net for IBD, ridge for RA (weak signal)   } } save(result,project,file=file.path(path,\"results\",\"application.RData\"))  writeLines(text=capture.output(utils::sessionInfo(),cat(\"\\n\"),       sessioninfo::session_info()),con=paste0(path,\"/results/info_app.txt\"))  # debugging if(FALSE){ set.seed(1) codes <- project[[\"RA\"]] test <- wrap_xrnet(x=x[codes],y=y[codes],alpha.init=0.95,alpha=1)    } #<<setup>>  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_app.eps\"),width=6.5,height=4,horizontal=FALSE,onefile=FALSE,paper=\"special\") graphics::par(mfrow=c(2,1),mar=c(4,2,1,1),oma=c(0,0,0,0)) load(file.path(path,paste0(\"results/application.RData\")),verbose=TRUE)  model0 <- \"wrap_glmtrans\" model1 <- \"sparselink\" model2 <- \"wrap_xrnet\"  # predictivity metric <- lapply(result,function(x) do.call(what=\"rbind\",args=lapply(x,function(x) x$auc))) # DEV and AUC need different directions (increase=FALSE/TRUE)! metric <- do.call(what=\"rbind\",args=metric) metric <- metric/metric[,\"wrap_separate\"] #xlab <- refs[rownames(metric)] #names <- gsub(pattern=\"\",replacement=\"\\n\",x=unlist(project))  label <- gsub(pattern=\"IBD.|RA.\",replacement=\"\",x=gsub(pattern=\" \",replacement=\"\\n\",x=names(unlist(project)))) index <- match(x=rownames(metric),table=unlist(project))  xlab <- label[index] plot_change(x=xlab,y0=metric[,model0],y1=metric[,model1],y2=metric[,model2],main=\"metric\",increase=TRUE,cex.main=0.8) graphics::axis(side=1,at=length(project$IBD)+0.5,labels=\"|\",tick=FALSE,line=-0.25,font=2) graphics::abline(h=0.5,lty=2,col=\"grey\") graphics::abline(h=1,lty=2,col=\"grey\")  # sparsity nzero <- lapply(result,function(x) lapply(x,function(x) sapply(x$refit$coef,function(x) colSums(x!=0)))) nzero <- do.call(what=\"rbind\",args=do.call(what=\"c\",args=nzero)) plot_change(x=xlab,y0=nzero[,model0],y1=nzero[,model1],y2=nzero[,model2],main=\"sparsity\",increase=FALSE,cex.main=0.8) graphics::axis(side=1,at=length(project$IBD)+0.5,labels=\"|\",tick=FALSE,line=-0.25,font=2) graphics::abline(h=0,lty=2,col=\"grey\") grDevices::dev.off()  # percentage change # (reported in section 4 \"application\" subsection 4.3 \"transfer learning\")  disease <- ifelse(rownames(metric) %in% project$IBD,\"IBD\",ifelse(rownames(metric) %in% project$RA,\"RA\",NA))  #round(100*colMeans(metric)-100,digits=2) round(100*colMeans(metric[disease==\"IBD\",])-100,digits=2) round(100*colMeans(metric[disease==\"RA\",])-100,digits=2)  colMeans(nzero) colMeans(nzero[disease==\"IBD\",]) colMeans(nzero[disease==\"RA\",])  #--- revision: report AUC --- Reduce(f=\"+\",x=lapply(result$IBD,function(x) x$auc))/length(result$IBD) lapply(result,function(x) round(colMeans(Reduce(f=\"+\",x=lapply(x,function(x) x$auc))/length(result$IBD)),digits=2)) #<<setup>>  load(file.path(path,\"results\",\"application.RData\"))  coefs <- list() for(i in seq_along(result$IBD)){   coefs[[i]] <- result$IBD[[i]]$refit$coef$sparselink   colnames(coefs[[i]]) <- names(project$IBD)   rownames(coefs[[i]]) <- rownames(result$IBD[[1]]$refit$coef$wrap_glmtrans) # try to avoid this }  any <- rowSums(sapply(coefs,function(x) apply(x,1,function(x) any(x!=0))))!=0 for(i in seq_along(result$IBD)){   coefs[[i]] <- coefs[[i]][any,] } table <- Reduce(f=\"+\",x=coefs)/5  cex <- 0.7  grDevices::postscript(file=file.path(path,\"manuscript\",\"fig_coef.eps\"),width=7,height=4,horizontal=FALSE,onefile=FALSE,paper=\"special\") graphics::par(mfrow=c(1,1),mar=c(2.5,4.5,0.5,1.5),oma=c(0,0,0,0)) graphics::plot.new() graphics::plot.window(xlim=c(0.6,ncol(table)+0.4),ylim=c(0.5,nrow(table)+0.5)) col <- apply(table,1,function(x) ifelse(all(x<=0),\"blue\",ifelse(all(x>=0),\"red\",\"black\"))) colnames <- gsub(x=colnames(table),pattern=\" \",replacement=\"\\n\") graphics::mtext(text=colnames,side=1,at=seq_len(ncol(table)),cex=cex,line=1) rownames <- rownames(table) graphics::mtext(text=rownames,side=2,at=seq_len(nrow(table)),las=2,cex=cex,line=0.7,col=col) star <- rowSums(table!=0)>1 graphics::mtext(text=\"*\",side=2,at=which(star),line=-0.3) graphics::mtext(text=ifelse(col==\"blue\",\"-\",ifelse(col==\"red\",\"+\",\".\")),side=4,at=seq_len(nrow(table)),las=2,cex=cex,line=0.5,col=col) for(i in seq_len(nrow(table))){   for(j in seq_len(ncol(table))){     for(k in 1:5){       col <- ifelse(coefs[[k]][i,j]<0,\"blue\",ifelse(coefs[[k]][i,j]>0,\"red\",\"white\"))       cex <- pmax(sqrt(5*abs(coefs[[k]][i,j])),0.2)       graphics::points(x=j-(-3+k)*0.17,y=i,col=col,cex=cex,pch=16)     }   } } graphics::abline(v=seq(from=0.5,to=5.5,by=1)) grDevices::dev.off()"},{"path":"https://rauschenberger.github.io/sparselink/articles/article.html","id":"estimating-sparse-regression-models-in-multi-task-learning-and-transfer-learning-through-adaptive-penalisation","dir":"Articles","previous_headings":"","what":"Estimating sparse regression models in multi-task learning and transfer learning through adaptive penalisation","title":"Sparse regression for related problems","text":"Armin Rauschenberger\\(~^{1,2,*}\\) , Petr V. Nazarov\\(~^{1,\\dagger}\\) , Enrico Glaab\\(~^{2,\\dagger}\\) \\(^1\\)Bioinformatics Artificial Intelligence, Department Medical Informatics, Luxembourg Institute Health (LIH), Strassen, Luxembourg. \\(^2\\)Biomedical Data Science, Luxembourg Centre Systems Biomedicine (LCSB), University Luxembourg, Esch-sur-Alzette, Luxembourg. \\(^{*}\\)correspondence addressed. \\(^{\\dagger}\\)Petr V. Nazarov Enrico Glaab share senior authorship.","code":""},{"path":"https://rauschenberger.github.io/sparselink/articles/article.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"Sparse regression for related problems","text":"propose simple two-stage procedure sharing information related high-dimensional prediction classification problems. stages, perform sparse regression separately problem. done without prior information first stage, use coefficients first stage prior information second stage. Specifically, designed feature-specific sign-specific adaptive weights share information feature selection, effect directions effect sizes different problems. proposed approach applicable multi-task learning well transfer learning. provides sparse models (.e., non-zero coefficients problem) easy interpret. show simulation application tends select fewer features achieving similar predictive performance compared available methods. implementation available R package ‘sparselink’ (https://github.com/rauschenberger/sparselink).","code":""},{"path":"https://rauschenberger.github.io/sparselink/articles/article.html","id":"full-text","dir":"Articles","previous_headings":"","what":"Full text","title":"Sparse regression for related problems","text":"Rauschenberger et al. (2025). “Estimating sparse regression models multi-task learning transfer learning adaptive penalisation”. revision. (Available ORBilu.)","code":""},{"path":"https://rauschenberger.github.io/sparselink/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Armin Rauschenberger. Author, maintainer.","code":""},{"path":"https://rauschenberger.github.io/sparselink/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Armin Rauschenberger, Petr V. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision","code":"@Article{,   title = {Estimating sparse regression models in multi-task learning and transfer learning through adaptive penalisation},   author = {Armin Rauschenberger and Petr V. Nazarov and Enrico Glaab},   journal = {Under revision},   year = {2025},   volume = {X},   number = {X},   pages = {X}, }"},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"sparse-regression-for-related-problems","dir":"","previous_headings":"","what":"Sparse Regression for Related Problems","title":"Sparse Regression for Related Problems","text":"Estimates sparse regression models (.e., non-zero coefficients) high-dimensional multi-task learning transfer learning settings","code":""},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Sparse Regression for Related Problems","text":"Install current release CRAN: latest development version GitHub: repository mirrored two institutional GitLab instances (see LIH LCSB).","code":"#install.packages(\"sparselink\") # not yet available #install.packages(\"remotes\") remotes::install_github(\"rauschenberger/sparselink\")"},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"reference","dir":"","previous_headings":"","what":"Reference","title":"Sparse Regression for Related Problems","text":"Armin Rauschenberger , Petr V. Nazarov , Enrico Glaab  (2025). “Estimating sparse regression models multi-task learning transfer learning adaptive penalisation”. Manuscript preparation.","code":""},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"reproducibility","dir":"","previous_headings":"","what":"Reproducibility","title":"Sparse Regression for Related Problems","text":"code reproducing simulations applications shown manuscript available vignette (analysis). installing package remotes::install_github(\"rauschenberger/sparselink\",build_vignettes=TRUE) restarting R, vignette can also loaded vignette(topic=\"analysis\",package=\"sparselink\").","code":""},{"path":"https://rauschenberger.github.io/sparselink/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Sparse Regression for Related Problems","text":"R package sparselink implements sparse regression related problems (Rauschenberger et al., 2025). Copyright © 2025 Armin Rauschenberger; Luxembourg Institute Health (LIH), Department Medical Informatics (DMI), Bioinformatics Artificial Intelligence (BioAI); University Luxembourg, Luxembourg Centre Systems Biomedicine (LCSB), Biomedical Data Science (BDS) Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/calc_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate deviance — calc_metric","title":"Calculate deviance — calc_metric","text":"Calculates Gaussian deviance (mean-squared error) binomial deviance.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/calc_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate deviance — calc_metric","text":"","code":"calc_metric(y, y_hat, family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/calc_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate deviance — calc_metric","text":"y response y_hat predictor family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/calc_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate deviance — calc_metric","text":"Returns scalar.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/calc_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate deviance — calc_metric","text":"","code":"n <- 100 family <- \"gaussian\" y <- stats::rnorm(n=n) y_hat <- stats::rnorm(n=n) calc_metric(y=y,y_hat=y_hat,family=family) #> [1] 2.170289  family <- \"binomial\" y <- stats::rbinom(n=n,size=1,prob=0.5) y_hat <- stats::runif(n=n) calc_metric(y=y,y_hat=y_hat,family=family) #> [1] 0.9851105"},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression Coefficients — coef.sparselink","title":"Regression Coefficients — coef.sparselink","text":"Extracts coefficients multi-task transfer learning regression model.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression Coefficients — coef.sparselink","text":"","code":"# S3 method for class 'sparselink' coef(object, ...)"},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression Coefficients — coef.sparselink","text":"object object class \"sparselink\" (generated function sparselink) ... (applicable)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regression Coefficients — coef.sparselink","text":"Returns estimated coefficients. output list two slots: slot alpha estimated intercept (vector length \\(q\\)), slot beta estimated slopes (matrix \\(p\\) rows \\(q\\) columns).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regression Coefficients — coef.sparselink","text":"Armin Rauschenberger, Petr N. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision. https://hdl.handle.net/10993/63425","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/coef.sparselink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression Coefficients — coef.sparselink","text":"","code":"family <- \"gaussian\" type <- \"multiple\" #  try \"multiple\" or \"transfer\" if(type==\"multiple\"){  data <- sim_data_multi(family=family) } else if(type==\"transfer\"){  data <- sim_data_trans(family=family) } object <- sparselink(x=data$X_train,y=data$y_train,family=family) #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold coef <- coef(object=object)"},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_penfacs.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct penalty factors — construct_penfacs","title":"Construct penalty factors — construct_penfacs","text":"Uses internal external weights well internal external exponents factors weights construct penalty factors.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_penfacs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct penalty factors — construct_penfacs","text":"","code":"construct_penfacs(w_int, w_ext, v_int, v_ext, type)"},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_penfacs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct penalty factors — construct_penfacs","text":"w_int internal weights: numeric vector length \\(p\\) non-negative entries w_ext external weights: numeric vector length \\(p\\) non-negative entries v_int exponent factor internal weights: non-negative scalar v_ext exponent factor external weights: non-negative scalar type scaling weights: character \"exp\", \"ari\", \"geo\", \"rem\" (without addition \".con\"), default: \"exp\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_penfacs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct penalty factors — construct_penfacs","text":"Returns vector length \\(q\\) (non-negative entries).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_penfacs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Construct penalty factors — construct_penfacs","text":"internal weights problem interest (\"supported\" problem), external weights problems (\"supporting\" problems). Multiple options exist scaling prior weights: \"exp\": \\(w_{int}^{v_{int}}+w_{ext}^{v_{ext}}\\) \"ari\": \\(v_{int} w_{int} + v_{ext} w_{ext}\\) \"geo\": \\(w_{int}^{v_{int}} w_{ext}^{v_{ext}}\\) \"rem\": \\(w_{int}^{v_{int}}+w_{ext}^{v_{ext}}-\\mathbb{}(v_{int}=0)-\\mathbb{}(v_{ext}=0))\\) constrained versions \"exp.con\", \"ari.con\", \"geo.con\", \"rem.con\" impose \\(v_{int}+v_{ext}=1\\). penalty factors inverse weights. Suggested choices \"exp\" predictivity \"ari.con\" interpretability.","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_penfacs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct penalty factors — construct_penfacs","text":"","code":"n <- 10 w_int <- stats::runif(n) w_ext <- stats::runif(n) construct_penfacs(w_int,w_ext,v_int=0.5,v_ext=0.5,type=\"exp\") #>  [1] 1.2267311 0.9974431 1.3570062 0.8043538 0.7102065 0.7760143 0.6372535 #>  [8] 0.6574816 0.7248686 0.8362442"},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct internal and external weights — construct_weights","title":"Construct internal and external weights — construct_weights","text":"Construct internal external weights","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct internal and external weights — construct_weights","text":"","code":"construct_weights(coef, id)"},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct internal and external weights — construct_weights","text":"coef matrix \\(p\\) rows (features) \\(q\\) columns (problems) id integer \\(1,\\ldots,q\\)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct internal and external weights — construct_weights","text":"Returns list slots lower.limits, upper.limits, weight.source (external weights) weight.target (internal weights). slot vector length \\(2*p\\), first \\(p\\) entries positive effects last \\(p\\) entries negative effects.","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/construct_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct internal and external weights — construct_weights","text":"","code":"p <- 10 q <- 3 data <- stats::rbinom(p*q,size=1,prob=0.2)*stats::rnorm(p*q) coef <- matrix(data=data,nrow=p,ncol=q) construct_weights(coef=coef,id=1) #> $lower.limits #>  [1]    0    0    0    0    0    0    0    0    0    0 -Inf -Inf -Inf -Inf -Inf #> [16] -Inf -Inf -Inf -Inf -Inf #>  #> $upper.limits #>  [1] Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf   0   0   0   0   0   0   0   0   0 #> [20]   0 #>  #> $weight.source #>  [1] 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 #>  [9] 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 #> [17] 1.656015 0.000000 0.000000 0.000000 #>  #> $weight.target #>  [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>  [8] 0.2551809 0.0000000 0.0000000 0.0000000 0.7088655 0.0000000 0.0000000 #> [15] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>"},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Metrics for sign detection — count_vector","title":"Metrics for sign detection — count_vector","text":"Calculates sensitivity, specificity precision ternary data (-1 negative effect, 0 effect, 1 positive effect).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metrics for sign detection — count_vector","text":"","code":"count_vector(truth, estim)  count_matrix(truth, estim)"},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metrics for sign detection — count_vector","text":"truth () vector length \\(p\\) (ii) \\(n \\times p\\) matrix entries -1, 0, 1 estim () vector length \\(p\\) (ii) \\(n \\times p\\) matrix entries -1, 0, 1","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Metrics for sign detection — count_vector","text":"Returns named vector length 3.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/count_vector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Metrics for sign detection — count_vector","text":"","code":"truth <- sample(x=c(-1,0,1),size=20,replace=TRUE) estim <- sample(x=c(-1,0,1),size=20,replace=TRUE) table(truth,estim) #>      estim #> truth -1 0 1 #>    -1  0 1 5 #>    0   3 4 0 #>    1   4 3 0 count_vector(truth,estim) #> sensitivity specificity   precision  #>   0.0000000   0.5714286   0.0000000"},{"path":"https://rauschenberger.github.io/sparselink/reference/cv_multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison — cv_multiple","title":"Model comparison — cv_multiple","text":"Compares predictive methods multi-task learning (cv_multiple) transfer learning (cv_transfer) \\(k\\)-fold cross-validation.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/cv_multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison — cv_multiple","text":"","code":"cv_multiple(   y,   X,   family,   alpha = 1,   nfolds = 10,   method = c(\"wrap_separate\", \"wrap_mgaussian\", \"sparselink\", \"wrap_spls\"),   alpha.init = 0.95,   type = \"exp\",   cands = NULL )  cv_transfer(   y,   X,   family,   alpha = 1,   nfolds = 10,   method = c(\"wrap_separate\", \"wrap_glmtrans\", \"sparselink\", \"wrap_xrnet\"),   alpha.init = 0.95,   type = \"exp\",   cands = NULL )"},{"path":"https://rauschenberger.github.io/sparselink/reference/cv_multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison — cv_multiple","text":"y \\(n \\times q\\) matrix (multi-task learning) list \\(n_k\\)-dimensional vectors (transfer learning) family character \"gaussian\" \"binomial\" alpha elastic net mixing parameter final regressions, default: 1 (lasso) nfolds number internal cross-validation folds, default: 10 (10-fold cross-validation) alpha.init elastic net mixing parameter initial regressions, default: 0.95 (lasso-like elastic net) type default \"exp\" scales weights \\(w_{ext}^{v_{ext}}+w_{int}^{v_{int}}\\) (see internal function construct_penfacs details) cands candidate values scaling parameters, default: NULL ({0, 0.2, 0.4, 0.6, 0.8, 1})","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/cv_multiple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model comparison — cv_multiple","text":"Returns list slots deviance, auc (relevant family=\"binomial\"), refit.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/cv_multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model comparison — cv_multiple","text":"","code":"#--- multi-task learning --- # \\donttest{ family <- \"gaussian\" data <- sim_data_multi(family=family) metric <- cv_multiple(y=data$y_train,X=data$X_train,family=family) #> fold 1 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 2 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 3 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 4 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 5 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 6 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 7 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 8 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 9 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> fold 10 #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls #> refit on all folds #> method: wrap_separate #> method: wrap_mgaussian #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_spls metric$deviance# } #>      wrap_separate wrap_mgaussian sparselink wrap_spls #> [1,]      1.786007       1.563429   1.341154  1.847301 #> [2,]      1.990516       2.132396   1.875813  2.790048 #> [3,]      1.871850       2.455214   1.408095  4.112216  #--- transfer learning --- # \\donttest{ family <- \"gaussian\" data <- sim_data_trans(family=family) metric <- cv_transfer(y=data$y_train,X=data$X_train,family=family) #> fold 1 #> method: wrap_separate #> method: wrap_glmtrans #> Registered S3 methods overwritten by 'caret': #>   method         from #>   predict.splsda spls #>   print.splsda   spls #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 2 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 3 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 4 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 5 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 6 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 7 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 8 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 9 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> fold 10 #> method: wrap_separate #> method: wrap_glmtrans #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet #> refit on all folds #> method: wrap_separate #> method: wrap_glmtrans #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> method: wrap_xrnet metric$deviance# } #>      wrap_separate wrap_glmtrans sparselink wrap_xrnet #> [1,]      4.878054      5.951404   2.311250   4.571539 #> [2,]      3.789215      3.662247   2.853324   4.158388 #> [3,]      1.338142      1.462901   1.135744   1.398073"},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Data fusion — fuse_data","title":"Data fusion — fuse_data","text":"Data fusion","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data fusion — fuse_data","text":"","code":"fuse_data(x, y = NULL, foldid = NULL)"},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data fusion — fuse_data","text":"x list \\(q\\) matrices, \\(n_1,\\ldots,n_q\\) rows \\(p\\) columns y list \\(q\\) vectors, length \\(n_1,\\ldots,n_q\\), NULL (default) foldid list \\(q\\) vectors, length \\(n_1,\\ldots,n_q\\), NULL (default)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data fusion — fuse_data","text":"Returns list concatenated feature matrices slot x (\\((\\sum_i^q n_i) \\times p\\) matrix), concatenated target vectors slot y (vector length \\((\\sum_i^q n_i)\\)), indices problems slot index (vector length \\((\\sum_i^q n_i)\\) entries \\(1,\\ldots,q\\)).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/fuse_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data fusion — fuse_data","text":"","code":"data <- sim_data_trans() sapply(X=data$y_train,FUN=length) #> [1]  50 100 200 sapply(X=data$X_train,FUN=dim) #>      [,1] [,2] [,3] #> [1,]   50  100  200 #> [2,]  200  200  200 fuse <- fuse_data(x=data$X_train,y=data$y_train) length(fuse$y) #> [1] 350 dim(fuse$x) #> [1] 350 200 table(fuse$index) #>  #>   1   2   3  #>  50 100 200"},{"path":"https://rauschenberger.github.io/sparselink/reference/get_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract dimensionality. — get_info","title":"Extract dimensionality. — get_info","text":"Extract dimensionality.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/get_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract dimensionality. — get_info","text":"","code":"get_info(x, y)"},{"path":"https://rauschenberger.github.io/sparselink/reference/get_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract dimensionality. — get_info","text":"x list \\(q\\) matrices, \\(n_k\\) (samples) rows \\(p\\) columns (features), \\(k\\) \\(1,\\ldots,q\\) y list \\(q\\) vectors, \\(n_k\\) entries, \\(k\\) \\(1,\\ldots,q\\)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/get_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract dimensionality. — get_info","text":"Returns list slots \\(q\\) (scalar, number problems), \\(n\\) (vector length \\(q\\), number samples) \\(p\\) (scalar, number features)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/get_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract dimensionality. — get_info","text":"","code":"data <- sim_data_trans() get_info(x=data$X_train,y=data$y_train) #> $q #> [1] 3 #>  #> $n #> [1]  50 100 200 #>  #> $p #> [1] 200 #>"},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Link function — link_function","title":"Link function — link_function","text":"Applies link function.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Link function — link_function","text":"","code":"link_function(mu, family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Link function — link_function","text":"mu numeric vector (values unit interval family=\"binomial\") family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Link function — link_function","text":"Returns numeric vector transformed values.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/link_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Link function — link_function","text":"","code":"family <- \"binomial\" from <- ifelse(family==\"binomial\",0,-3) to <- ifelse(family==\"binomial\",1,3) mu <- seq(from=from,to=to,length.out=100) eta <- link_function(mu=mu,family=family) graphics::plot(x=mu,y=eta,type=\"l\",main=family) v <- ifelse(family==\"binomial\",0.5,0) graphics::abline(v=v,lty=2) graphics::abline(h=0,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"logit function — logit","title":"logit function — logit","text":"logit function","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logit function — logit","text":"","code":"logit(x)"},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logit function — logit","text":"x numeric vector values unit interval","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"logit function — logit","text":"Returns numeric vector transformed values.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"logit function — logit","text":"","code":"x <- seq(from=0,to=1,length.out=100) y <- logit(x=x) graphics::plot(x=x,y=y,type=\"l\") graphics::abline(v=0.5,lty=2) graphics::abline(h=0,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/make_folds_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Create folds for multi-task and transfer learning — make_folds_multi","title":"Create folds for multi-task and transfer learning — make_folds_multi","text":"Create folds multi-task transfer learning","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/make_folds_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create folds for multi-task and transfer learning — make_folds_multi","text":"","code":"make_folds_multi(y, family, nfolds = 10)  make_folds_trans(y, family, nfolds = 10)"},{"path":"https://rauschenberger.github.io/sparselink/reference/make_folds_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create folds for multi-task and transfer learning — make_folds_multi","text":"y multi-task learning: y matrix \\(n\\) rows (samples) \\(q\\) columns (outcomes) transfer learning: list \\(q\\) numeric vectors length \\(n_1,\\ldots,n_q\\) family character \"gaussian\" \"binomial\" nfolds integer 2 \\(n\\)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/make_folds_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create folds for multi-task and transfer learning — make_folds_multi","text":"Returns fold identifiers vector length \\(n\\) entries 1,\\(\\ldots\\),nfolds (multi-task learning) list \\(q\\) vectors lengths \\(n_1,\\ldots,n_q\\) (transfer learning).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/make_folds_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create folds for multi-task and transfer learning — make_folds_multi","text":"","code":"#--- multi-task learning --- family <- \"binomial\" y <- sim_data_multi(family=family)$y_train fold <- make_folds_multi(y=y,family=family)  #--- transfer learning --- family <- \"binomial\" y <- sim_data_trans(family=family)$y_train fold <- make_folds_trans(y,family=family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean function — mean_function","title":"Mean function — mean_function","text":"Applies mean function (inverse link function).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean function — mean_function","text":"","code":"mean_function(eta, family)"},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean function — mean_function","text":"eta numeric vector family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean function — mean_function","text":"Returns numeric vector transformed values.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/mean_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean function — mean_function","text":"","code":"family <- \"binomial\" eta <- seq(from=-3,to=3,length.out=100) mu <- mean_function(eta=eta,family=family) graphics::plot(x=eta,y=mu,type=\"l\",main=family) graphics::abline(v=0,lty=2) h <- ifelse(family==\"binomial\",0.5,0) graphics::abline(h=h,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Available methods — methods","title":"Available methods — methods","text":"Wrapper functions available methods related problems.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Available methods — methods","text":"","code":"wrap_empty(x, y, family, alpha = 1)  wrap_separate(x, y, family, alpha = 1, lambda = NULL)  # S3 method for class 'wrap_separate' predict(object, newx, ...)  # S3 method for class 'wrap_separate' coef(object, ...)  wrap_common(x, y, family, alpha = 1)  # S3 method for class 'wrap_common' predict(object, newx, ...)  # S3 method for class 'wrap_common' coef(object, ...)  wrap_mgaussian(x, y, family = \"gaussian\", alpha = 1)  # S3 method for class 'wrap_mgaussian' predict(object, newx, ...)  # S3 method for class 'wrap_mgaussian' coef(object, ...)  wrap_spls(x, y, family = \"gaussian\", alpha = 1, nfolds = 10)  # S3 method for class 'wrap_spls' predict(object, newx, ...)  # S3 method for class 'wrap_spls' coef(object, ...)  wrap_glmtrans(x, y, family = \"gaussian\", alpha = 1)  # S3 method for class 'wrap_glmtrans' predict(object, newx, ...)  # S3 method for class 'wrap_glmtrans' coef(object, ...)  wrap_xrnet(   x,   y,   alpha.init = 0.95,   alpha = 1,   nfolds = 10,   family = \"gaussian\" )  # S3 method for class 'wrap_xrnet' predict(object, newx, ...)  # S3 method for class 'wrap_xrnet' coef(object, ...)"},{"path":"https://rauschenberger.github.io/sparselink/reference/methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Available methods — methods","text":"x feature matrix (multi-task learning) list \\(q\\) feature matrices (transfer learning) y response matrix (multi-task learning) list \\(q\\) response vectors (transfer learning) family character vector 1 \\(q\\) entries, possible values \"gaussian\" sometimes \"binomial\" alpha elastic net mixing parameter: number 0 1 lambda sequence regularisation parameters object output multi-task learning transfer learning method newx feature matrix (MTL) list feature matrices (TL) testing samples ... (applicable) nfolds number cross-validation folds: positive integer alpha.init elastic net mixing parameter initial models: number 0 1","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Available methods — methods","text":"wrapper functions wrap_empty, wrap_separate, wrap_common, wrap_mgaussian, wrap_spls, wrap_glmtrans, wrap_xrnet return fitted models, generic functions coef predict return coefficients predicted values standardised format.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/methods.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Available methods — methods","text":"wrap_empty(): intercept-model (MTL TL) wrap_separate(): separate model problem (MTL TL) wrap_common(): common model problems (TL) wrap_mgaussian(): multivariate Gaussian regression (MTL) wrap_spls(): sparse partial least squares (MTL) wrap_glmtrans(): transfer generalised linear model (TL) wrap_xrnet(): hierarchical regression (TL)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/methods.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Available methods — methods","text":"Noah Simon, Jerome H. Friedman, Trevor Hastie (2013). arXiv (Preprint). doi:10.48550/arXiv.1311.6529 . (cv.glmnet) Hyonho Chun Sündüz Keleş (2010). \"Sparse Partial Least Squares Regression Simultaneous Dimension Reduction Variable Selection\". Journal Royal Statistical Society Series B: Statistical Methodology 72(1);3–25. doi:10.1111/j.1467-9868.2009.00723.x . (spls) Ye Tian Yang Feng (2022). \"Transfer learning high-dimensional generalized linear models\". Journal American Statistical Association 118(544):2684-2697. doi:10.1080/01621459.2022.2071278 . (glmtrans) Garrett M. Weaver Juan Pablo Lewinger (2019). \"xrnet: Hierarchical Regularized Regression Incorporate External Data\". Journal Open Source Software 4(44):1761. doi:10.21105/joss.01761 . (xrnet)","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Available methods — methods","text":"","code":"#--- multi-task learning --- n_train <- 100 n_test <- 10 p <- 50 q <- 3 family <- \"gaussian\" x <- matrix(data=rnorm(n=n_train*p),nrow=n_train,ncol=p) newx <- matrix(data=rnorm(n=n_test*p),nrow=n_test,ncol=p) y <- matrix(data=rnorm(n_train*q),nrow=n_train,ncol=q) object <- wrap_empty(x=x,y=y,family=family) model <- \"empty\" # try \"empty\", \"separate\", \"mgaussian\" or \"spls\" if(model==\"empty\"){   object <- wrap_empty(x=x,y=y,family=family) } else if(model==\"separate\"){   object <- wrap_separate(x=x,y=y,family=family) } else if(model==\"mgaussian\"){   object <- wrap_mgaussian(x=x,y=y,family=family) } else if(model==\"spls\"){   object <- wrap_spls(x=x,y=y,family=family) } coef(object) #> $alpha #> [1] -0.10581259  0.15089275  0.00960871 #>  #> $beta #>       [,1] [,2] [,3] #>  [1,]    0    0    0 #>  [2,]    0    0    0 #>  [3,]    0    0    0 #>  [4,]    0    0    0 #>  [5,]    0    0    0 #>  [6,]    0    0    0 #>  [7,]    0    0    0 #>  [8,]    0    0    0 #>  [9,]    0    0    0 #> [10,]    0    0    0 #> [11,]    0    0    0 #> [12,]    0    0    0 #> [13,]    0    0    0 #> [14,]    0    0    0 #> [15,]    0    0    0 #> [16,]    0    0    0 #> [17,]    0    0    0 #> [18,]    0    0    0 #> [19,]    0    0    0 #> [20,]    0    0    0 #> [21,]    0    0    0 #> [22,]    0    0    0 #> [23,]    0    0    0 #> [24,]    0    0    0 #> [25,]    0    0    0 #> [26,]    0    0    0 #> [27,]    0    0    0 #> [28,]    0    0    0 #> [29,]    0    0    0 #> [30,]    0    0    0 #> [31,]    0    0    0 #> [32,]    0    0    0 #> [33,]    0    0    0 #> [34,]    0    0    0 #> [35,]    0    0    0 #> [36,]    0    0    0 #> [37,]    0    0    0 #> [38,]    0    0    0 #> [39,]    0    0    0 #> [40,]    0    0    0 #> [41,]    0    0    0 #> [42,]    0    0    0 #> [43,]    0    0    0 #> [44,]    0    0    0 #> [45,]    0    0    0 #> [46,]    0    0    0 #> [47,]    0    0    0 #> [48,]    0    0    0 #> [49,]    0    0    0 #> [50,]    0    0    0 #>  predict(object,newx=newx) #> [[1]] #>       lambda.min #>  [1,] -0.1058126 #>  [2,] -0.1058126 #>  [3,] -0.1058126 #>  [4,] -0.1058126 #>  [5,] -0.1058126 #>  [6,] -0.1058126 #>  [7,] -0.1058126 #>  [8,] -0.1058126 #>  [9,] -0.1058126 #> [10,] -0.1058126 #>  #> [[2]] #>       lambda.min #>  [1,]  0.1508927 #>  [2,]  0.1508927 #>  [3,]  0.1508927 #>  [4,]  0.1508927 #>  [5,]  0.1508927 #>  [6,]  0.1508927 #>  [7,]  0.1508927 #>  [8,]  0.1508927 #>  [9,]  0.1508927 #> [10,]  0.1508927 #>  #> [[3]] #>       lambda.min #>  [1,] 0.00960871 #>  [2,] 0.00960871 #>  [3,] 0.00960871 #>  [4,] 0.00960871 #>  [5,] 0.00960871 #>  [6,] 0.00960871 #>  [7,] 0.00960871 #>  [8,] 0.00960871 #>  [9,] 0.00960871 #> [10,] 0.00960871 #>   #--- transfer learning --- n_train <- c(100,50) n_test <- c(10,10) p <- 50 x <- lapply(X=n_train,function(n) matrix(data=stats::rnorm(n*p),nrow=n,ncol=p)) newx <- lapply(X=n_test,function(n) matrix(data=stats::rnorm(n*p),nrow=n,ncol=p)) y <- lapply(X=n_train,function(n) stats::rnorm(n)) family <- \"gaussian\" model <- \"empty\" # try \"empty\", \"separate\", \"common\", \"glmtrans\", or \"xrnet\" if(model==\"empty\"){  object <- wrap_empty(x=x,y=y,family=family) } else if(model==\"separate\"){  object <- wrap_separate(x=x,y=y,family=family) } else if(model==\"common\"){  object <- wrap_common(x=x,y=y,family=family) } else if(model==\"glmtrans\"){  object <- wrap_glmtrans(x=x,y=y,family=family) } else if(model==\"xrnet\"){  object <- wrap_xrnet(x=x,y=y,family=family) } coef(object) #> $alpha #> [1] -0.03171024 -0.21167258 #>  #> $beta #>       [,1] [,2] #>  [1,]    0    0 #>  [2,]    0    0 #>  [3,]    0    0 #>  [4,]    0    0 #>  [5,]    0    0 #>  [6,]    0    0 #>  [7,]    0    0 #>  [8,]    0    0 #>  [9,]    0    0 #> [10,]    0    0 #> [11,]    0    0 #> [12,]    0    0 #> [13,]    0    0 #> [14,]    0    0 #> [15,]    0    0 #> [16,]    0    0 #> [17,]    0    0 #> [18,]    0    0 #> [19,]    0    0 #> [20,]    0    0 #> [21,]    0    0 #> [22,]    0    0 #> [23,]    0    0 #> [24,]    0    0 #> [25,]    0    0 #> [26,]    0    0 #> [27,]    0    0 #> [28,]    0    0 #> [29,]    0    0 #> [30,]    0    0 #> [31,]    0    0 #> [32,]    0    0 #> [33,]    0    0 #> [34,]    0    0 #> [35,]    0    0 #> [36,]    0    0 #> [37,]    0    0 #> [38,]    0    0 #> [39,]    0    0 #> [40,]    0    0 #> [41,]    0    0 #> [42,]    0    0 #> [43,]    0    0 #> [44,]    0    0 #> [45,]    0    0 #> [46,]    0    0 #> [47,]    0    0 #> [48,]    0    0 #> [49,]    0    0 #> [50,]    0    0 #>  predict(object,newx=newx) #> [[1]] #>        lambda.min #>  [1,] -0.03171024 #>  [2,] -0.03171024 #>  [3,] -0.03171024 #>  [4,] -0.03171024 #>  [5,] -0.03171024 #>  [6,] -0.03171024 #>  [7,] -0.03171024 #>  [8,] -0.03171024 #>  [9,] -0.03171024 #> [10,] -0.03171024 #>  #> [[2]] #>       lambda.min #>  [1,] -0.2116726 #>  [2,] -0.2116726 #>  [3,] -0.2116726 #>  [4,] -0.2116726 #>  [5,] -0.2116726 #>  [6,] -0.2116726 #>  [7,] -0.2116726 #>  [8,] -0.2116726 #>  [9,] -0.2116726 #> [10,] -0.2116726 #>"},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_change.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise differences — plot_change","title":"Pairwise differences — plot_change","text":"Visualises differences within sets three values different settings.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_change.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise differences — plot_change","text":"","code":"plot_change(   x,   y0,   y1,   y2,   dist = 0.15,   main = \"\",   cex.axis = 0.5,   cex.main = 1,   increase = TRUE )"},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_change.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise differences — plot_change","text":"x setting: character vector y0 values left: numeric vector y1 values centre: numeric vector y2 values right: numeric vector dist horizontal distance points main title cex.axis numeric cex.main numeric increase change arrow NULL, , ","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_change.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pairwise differences — plot_change","text":"Returns NULL. Generates plot.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_change.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise differences — plot_change","text":"","code":"m <- 3 # number of settings n <- 5 # number of repetitions x <- rep(LETTERS[1:m],each=n) y0 <- stats::rnorm(n*m,mean=0) y1 <- stats::rnorm(n*m,mean=ifelse(x==\"A\",2,-2)) y2 <- stats::rnorm(n*m,mean=ifelse(x==\"A\",4,-4)) plot_change(x,y0,y1,y2)  #> NULL"},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualise metric that depends on two parameters — plot_weight","title":"Visualise metric that depends on two parameters — plot_weight","text":"Displays values y grey scale (white=lowest, black=highest), different combinations two variables x. lowest value indicated red cross, lowest value diagonal indicated red circle.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualise metric that depends on two parameters — plot_weight","text":"","code":"plot_weight(x, y)"},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualise metric that depends on two parameters — plot_weight","text":"x list slots source target y numeric vector","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_weight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualise metric that depends on two parameters — plot_weight","text":"Returns NULL. Generates plot.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/plot_weight.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualise metric that depends on two parameters — plot_weight","text":"","code":"values <- seq(from=0,to=1,by=0.2) x <- expand.grid(source=values,target=values) y <- stats::rexp(n=length(values)*length(values)) plot_weight(x=x,y=y)  #> NULL"},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-sample Predictions — predict.sparselink","title":"Out-of-sample Predictions — predict.sparselink","text":"Predicts outcomes multi-task transfer learning regression model.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-sample Predictions — predict.sparselink","text":"","code":"# S3 method for class 'sparselink' predict(object, newx, weight = NULL, ...)"},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Out-of-sample Predictions — predict.sparselink","text":"object object class \"sparselink\" (generated function sparselink) newx features: matrix \\(n\\) rows (samples) \\(p\\) columns (variables) multi-task learning; list \\(q\\) matrices \\(n_k\\) rows (samples) \\(p\\) columns (variables) transfer learning, \\(k\\) \\(1,\\ldots,q\\) weight hyperparameters scaling external internal weights: numeric vector length 2, first entry external weights (prior coefficients source data), second entry internal weights (prior coefficients target data), selected values must among candidate values, default: NULL (using cross-validated weights) ... (applicable)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Out-of-sample Predictions — predict.sparselink","text":"Returns predicted values predicted probabilities. output list \\(q\\) column vectors length \\(n_k\\) \\(k\\) \\(1,\\ldots,q\\). vector corresponds one target (multi-task learning) one dataset (transfer learning).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Out-of-sample Predictions — predict.sparselink","text":"Armin Rauschenberger, Petr N. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision. https://hdl.handle.net/10993/63425","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/predict.sparselink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Out-of-sample Predictions — predict.sparselink","text":"","code":"family <- \"gaussian\" type <- \"multiple\" # try \"multiple\" or \"transfer\" if(type==\"multiple\"){  data <- sim_data_multi(family=family) } else if(type==\"transfer\"){  data <- sim_data_trans(family=family) } object <- sparselink(x=data$X_train,y=data$y_train,family=family) #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold y_hat <- predict(object=object,newx=data$X_test)"},{"path":"https://rauschenberger.github.io/sparselink/reference/print.sparselink.html","id":null,"dir":"Reference","previous_headings":"","what":"Print sparselink object — print.sparselink","title":"Print sparselink object — print.sparselink","text":"Prints object class sparselink","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/print.sparselink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print sparselink object — print.sparselink","text":"","code":"# S3 method for class 'sparselink' print(x, ...)"},{"path":"https://rauschenberger.github.io/sparselink/reference/print.sparselink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print sparselink object — print.sparselink","text":"x object class sparselink (generated function sparselink) ... (applicable)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/print.sparselink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print sparselink object — print.sparselink","text":"Returns NULL. Writes information sparselink-object console.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/print.sparselink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print sparselink object — print.sparselink","text":"","code":"n <- 100; p <- 50; q <- 3 family <- \"gaussian\" x <- matrix(data=rnorm(n=n*p),nrow=n,ncol=p) y <- matrix(data=rnorm(n*q),nrow=n,ncol=q) object <- sparselink(x=x,y=y,family=family) #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) object #> sparselink-object: #> multi-task learning #> 3 problems (targets) #> 50 features"},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid function — sigmoid","title":"Sigmoid function — sigmoid","text":"Sigmoid function","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid function — sigmoid","text":"","code":"sigmoid(x)"},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid function — sigmoid","text":"x numeric vector","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sigmoid function — sigmoid","text":"Returns numeric vector transformed values.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid function — sigmoid","text":"","code":"x <- seq(from=-3,to=3,length.out=100) y <- sigmoid(x) graphics::plot(x=x,y=y,type=\"l\") graphics::abline(v=0,lty=2) graphics::abline(h=0.5,lty=2)"},{"path":"https://rauschenberger.github.io/sparselink/reference/sim_data_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Data simulation for related problems — sim_data_multi","title":"Data simulation for related problems — sim_data_multi","text":"Simulates data multi-task learning transfer learning.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim_data_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data simulation for related problems — sim_data_multi","text":"","code":"sim_data_multi(   prob.common = 0.05,   prob.separate = 0.05,   q = 3,   n0 = 100,   n1 = 10000,   p = 200,   rho = 0.5,   family = \"gaussian\" )  sim_data_trans(   prob.common = 0.05,   prob.separate = 0.05,   q = 3,   n0 = c(50, 100, 200),   n1 = 10000,   p = 200,   rho = 0.5,   family = \"gaussian\" )"},{"path":"https://rauschenberger.github.io/sparselink/reference/sim_data_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data simulation for related problems — sim_data_multi","text":"prob.common probability common effect (number 0 1) prob.separate probability separate effect (number 0 1) q number datasets: integer n0 number training samples: integer vector length \\(q\\) n1 number testing samples datasets: integer p number features: integer rho correlation (decreasing structure) family character \"gaussian\" \"binomial\"","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim_data_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data simulation for related problems — sim_data_multi","text":"Multi-task learning: Returns list slots y_train (\\(n_0 \\times q\\) matrix), X_train(\\(n_0 \\times p\\) matrix), y_test (\\(n_1 \\times q\\) matrix), X_test (\\(n_1 \\times p\\) matrix), beta (\\(p \\times q\\) matrix). Transfer learning: Returns list slots y_train (\\(q\\) vectors) X_train (\\(q\\) matrices \\(p\\) columns) training data, y_test (\\(vectors\\)) X_test (\\(q\\) matrices \\(p\\) columns) testing data, beta effects (\\(p \\times q\\) matrix).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sim_data_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data simulation for related problems — sim_data_multi","text":"","code":"#--- multi-task learning --- data <- sim_data_multi() sapply(X=data,FUN=dim) #>      y_train X_train y_test X_test beta #> [1,]     100     100  10000  10000  200 #> [2,]       3     200      3    200    3  #--- transfer learning --- data <- sim_data_trans() sapply(X=data$y_train,FUN=length) #> [1]  50 100 200 sapply(X=data$X_train,FUN=dim) #>      [,1] [,2] [,3] #> [1,]   50  100  200 #> [2,]  200  200  200 sapply(X=data$y_test,FUN=length) #> [1] 10000 10000 10000 sapply(X=data$X_test,FUN=dim) #>       [,1]  [,2]  [,3] #> [1,] 10000 10000 10000 #> [2,]   200   200   200 dim(data$beta) #> [1] 200   3"},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse regression for related problems — sparselink-package","title":"Sparse regression for related problems — sparselink-package","text":"R package `sparselink` implements sparse regression related problems (multi-task learning transfer learning).","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sparse regression for related problems — sparselink-package","text":"Use function [sparselink()] model fitting. Type `library(sparselink)` `?sparselink` `help(\"sparselink\")` open help file. See vignette examples. Type `vignette(\"sparselink\")` `browseVignettes(\"sparselink\")` open vignette.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sparse regression for related problems — sparselink-package","text":"Armin Rauschenberger, Petr N. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision. https://hdl.handle.net/10993/63425","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sparse regression for related problems — sparselink-package","text":"Maintainer: Armin Rauschenberger armin.rauschenberger@lih.lu (ORCID)","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse regression for related problems — sparselink-package","text":"","code":"?sparselink ?coef.sparselink ?predict.sparselink"},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse regression for related problems — sparselink","title":"Sparse regression for related problems — sparselink","text":"Estimates sparse regression models (.e., performing feature selection) multi-task learning transfer learning. Multi-task learning involves multiple targets, transfer learning involves multiple datasets.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse regression for related problems — sparselink","text":"","code":"sparselink(   x,   y,   family,   alpha.init = 0.95,   alpha = 1,   type = \"exp\",   nfolds = 10,   cands = NULL )"},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse regression for related problems — sparselink","text":"x \\(n \\times p\\) matrix (multi-task learning) list \\(n_k \\times p\\) matrices (transfer learning) y \\(n \\times q\\) matrix (multi-task learning) list \\(n_k\\)-dimensional vectors (transfer learning) family character \"gaussian\" \"binomial\" alpha.init elastic net mixing parameter initial regressions, default: 0.95 (lasso-like elastic net) alpha elastic net mixing parameter final regressions, default: 1 (lasso) type default \"exp\" scales weights \\(w_{ext}^{v_{ext}}+w_{int}^{v_{int}}\\) (see internal function construct_penfacs details) nfolds number internal cross-validation folds, default: 10 (10-fold cross-validation) cands candidate values scaling parameters, default: NULL ({0, 0.2, 0.4, 0.6, 0.8, 1})","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparse regression for related problems — sparselink","text":"Returns object class sparselink, list multiple slots: Stage 1 regressions (sharing information): Slot glm.one contains \\(q\\) objects type cv.glmnet (one problem). Candidate scaling parameters (exponents): Slot weight contains data frame \\(n\\) combinations exponents external (source) internal (target) weights Stage 2 regressions (sharing information): Slot glm.two contains \\(q\\) lists (one problem) \\(n\\) objects type cv.glmnet (one combination exponents). Optimal regularisation parameters: Slot lambda.min contains cross-validated regularisation parameters stage 2 regressions. Optimal scaling parameters: Slots weight.ind weight.min indicate contain cross-validated scaling parameters.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sparse regression for related problems — sparselink","text":"Armin Rauschenberger, Petr N. Nazarov, Enrico Glaab (2025). \"Estimating sparse regression models multi-task learning transfer learning adaptive penalisation\". revision. https://hdl.handle.net/10993/63425","code":""},{"path":[]},{"path":"https://rauschenberger.github.io/sparselink/reference/sparselink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse regression for related problems — sparselink","text":"","code":"#--- multi-task learning --- n <- 100 p <- 200 q <- 3 family <- \"gaussian\" x <- matrix(data=rnorm(n=n*p),nrow=n,ncol=p) y <- matrix(data=rnorm(n*q),nrow=n,ncol=q) object <- sparselink(x=x,y=y,family=family) #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold  #--- transfer learning --- n <- c(100,50) p <- 200 x <- lapply(X=n,function(x) matrix(data=stats::rnorm(n*p),nrow=x,ncol=p)) y <- lapply(X=n,function(x) stats::rnorm(x)) family <- \"gaussian\" object <- sparselink(x=x,y=y,family=family) #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso) #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold #> Warning: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold"},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":null,"dir":"Reference","previous_headings":"","what":"Train and test model — traintest","title":"Train and test model — traintest","text":"Trains tests prediction models","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train and test model — traintest","text":"","code":"traintest(   y_train,   X_train,   y_test = NULL,   X_test = NULL,   family = \"gaussian\",   alpha = 1,   method = c(\"wrap_empty\", \"wrap_separate\", \"sparselink\"),   alpha.init = 0.95,   type = \"exp\",   cands = NULL )"},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train and test model — traintest","text":"y_train target training samples: \\(n \\times q\\) matrix (multi-task learning) list \\(q\\) vectors length \\(n_1,\\ldots,n_q\\) (transfer learning) X_train features training samples: \\(n \\times p\\) matrix (multi-task learning) list \\(q\\) matrices dimensions \\(n_1 \\times p,\\ldots,n_q \\times p\\) (transfer learning) y_test target testing samples: \\(m \\times p\\) matrix (multi-task learning) list \\(q\\) vectors length \\(m_1,\\ldots,m_q\\) (transfer learning) X_test features testing samples: \\(m \\times p\\) matrix (multi-task learning) list \\(q\\) matrices dimensions \\(m_1 \\times p,\\ldots,m_q \\times p\\) (transfer learning) family character \"gaussian\" \"binomial\" alpha elastic net mixing parameter final regressions, default: 1 (lasso) alpha.init elastic net mixing parameter initial regressions, default: 0.95 (lasso-like elastic net) type default \"exp\" scales weights \\(w_{ext}^{v_{ext}}+w_{int}^{v_{int}}\\) (see internal function construct_penfacs details) cands candidate values scaling parameters, default: NULL ({0, 0.2, 0.4, 0.6, 0.8, 1})","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train and test model — traintest","text":"Returns list computation time slot time, --sample deviance slot deviance, --sample ROC-AUC slot auc, coefficients slot coef, predicted value slot y_hat, optimal hyperparameters slot hyperpar.","code":""},{"path":"https://rauschenberger.github.io/sparselink/reference/traintest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Train and test model — traintest","text":"","code":"#--- multi-task learning --- # \\donttest{ family <- \"gaussian\" data <- sim_data_multi(family=family) result <- traintest(data$y_train,data$X_train,family=family)# } #> method: wrap_empty #> method: wrap_separate #> method: sparselink #> mode: multi-target learning, alpha.init=0.95 (elastic net), alpha=1 (lasso)  #--- transfer learning --- # \\donttest{ family <- \"gaussian\" data <- sim_data_trans(family=family) result <- traintest(data$y_train,data$X_train,family=family)# } #> method: wrap_empty #> method: wrap_separate #> method: sparselink #> mode: transfer learning, alpha.init=0.95 (elastic net), alpha=1 (lasso)"},{"path":"https://rauschenberger.github.io/sparselink/news/index.html","id":"sparselink-001-2024-11-29","dir":"Changelog","previous_headings":"","what":"sparselink 0.0.1 (2024-11-29)","title":"sparselink 0.0.1 (2024-11-29)","text":"development","code":""}]
